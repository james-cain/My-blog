# http/http2/https

## HTTP

### headers

#### 请求头

1. <u>Accept</u>：用来告知客户端可以处理的内容类型，这种内容类型用MIME类型来表示。借助内容协商机制，服务器可以从诸多备选项中选择一项进行应用，并使用**Content-Type**应答头通知客户端它的选择。

< MIME_type >/< MIME_subtype >

< MIME_type >/*

*/ * 任意类型的MIME类型

;q=(q因子权重)

如： text/html,application/xhtml+xml,application/xml;q=0.9, * /*;q=0.8

2. <u>Accept-Charset</u>：请求头用来告知（服务器）客户端可以处理的字符集类型。借助内容协商机制，服务器可以从诸多备选项中选择一项进行应用，并使用**Content-Type**应答头通知客户端它的选择。通常不会设置此项。

<**charset**> utf-8或iso-8895-1字符集

*** 通配符**

;q=

3. <u>Accept-Encoding</u>：将客户端能够理解的内容编码方式进行通知。使用并在相应报文首部**Content-Encoding**中通知客户端选择

压缩方式包括gzip（Lempel-Ziv coding压缩算法（LZ77）+32位CRC校验的编码方式）、compress（Lempel-Ziv-Welch（LZW））、deflate（zlib结构+deflate压缩算法）、br（Brotli算法）、identity（保持自身）、*（匹配其他任意未在首部字段中列出的编码方式）

identity不压缩存在两种情形：a.要发送的数据已经经过压缩，再次进行压缩不会导致被传输的数据量更小，如图像格式 b.服务器超载，无法承受压缩需求导致的计算开销，通常，如果服务器使用超过80%的计算能力，不建议压缩

4. Accept-Language：允许客户端声明它可以理解的自然语言，以及优先选择的区域方言，并使用**Content-Language**应答头通知客户端它的选择。

5. Accept-Ranges：标识自身支持范围请求（partial requests）。当浏览器发现Accept-Range头时，可以尝试继续中断了的下载，而不是重新开始

none：在一些浏览器，如IE9，会依据该头部去禁用或者移除下载管理器的暂停按钮

bytes

6. Access-Control-Allow-Credentials：表示是否可以将对请求的响应暴露给页面。Credentials可以是<u>cookies，authorization headers 或TLS client certificates</u>

当作为对预检请求的响应的一部分时，这能表示是否真正的请求可以使用credentials。注意GET请求**没有预检**，所以若对资源的请求带有了credentials，响应会被浏览器忽视

Access-Control-Allow-Credentials头需与XMLHttpRequest.withCredentials或Fetch api中的Request()构造器中的credentials选项结合使用

Access-Control-Allow-Credentials: true

使用带credentials的XHR：

```
var xhr = new XMLHttpRequest();
xhr.open('GET', 'http://example.com/', true);
xhr.withCredentials = true;
xhr.send(null);
```

使用带credentials的Fetch：

```
fetch(url, {
    credentials: 'include'
})
```

7. Access-Control-Allow-Headers：用于**预检请求**中，列出将会在正式请求的**Access-Control-Expose-Headers**字段中出现的首部信息

简单首部，如 [simple headers](https://developer.mozilla.org/en-US/docs/Glossary/simple_header)、[`Accept`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept)、[`Accept-Language`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept-Language)、[`Content-Language`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Language)、[`Content-Type`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type) （只限于解析后的值为 `application/x-www-form-urlencoded、``multipart/form-data `或 `text/plain 三种MIME类型（不包括参数）），它们始终是被支持的，不需要在这个首部特意列出。`

如果请求中含有 [`Access-Control-Request-Headers`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Access-Control-Request-Headers) 字段，那么这个首部是必要的。

8. Access-Control-Allow-Methods：对**预检请求**的应答明确了客户端所要访问的资源允许使用的方法或方法列表

Access-Control-Allow-Methods: POST,GET,OPTIONS

9. Access-Control-Allow-Origin：指定了该响应的资源是否允许与给定的origin共享

***** 允许所有域都具有访问资源的权限

<**origin**> 指定一个可以访问资源的URI

10. Access-Control-Expose-Headers：列出哪些首部可以作为响应的一部分暴露给外部

默认情况下，Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma简单响应首部是可以暴露给外部的，其他的首部需要在里面列出来

11. Access-Control-Max-Age：表示**预检请求**的返回结果（即Access-Control-Allow-Methods和Access-Control-Allow-Headers提供的信息）可以被缓存多久

在Firefox中，上限是24小时（即87400秒），在Chromium中则是10分钟（即600秒）还规定了默认值是5秒

若值为-1，表示禁用缓存。每一次请求都需要提供预检请求，即用OPTIONS请求进行预检

12. Access-Control-Request-Headers：出现在**预检请求**中，用于通知服务器在真正的请求中会采用哪些请求首部

13. Access-Control-Request-Method：出现在**预检请求**中，用于通知服务器在真正的请求中会采用哪种HTTP方法。因为预检请求所使用的方法总是OPTIONS，与实际请求所使用的方法不一样，**所以这个首部是必要的**

14. Age：消息头里包含消息对象在缓存代理中存储的时长，以秒为单位

Age消息头的值通常接近于0.表示此消息对象刚刚从原始服务器获取不久；其他的值表示代理服务器当前的系统时间与此应答消息中的通用**消息头Date**的值之差

15. Allow：用于枚举资源所支持的HTTP方法的集合

若服务器返回状态码 [`405`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/405) `Method Not Allowed，则该首部字段亦需要同时返回给客户端。如果` `Allow`  首部字段的值为空，说明资源不接受使用任何 HTTP 方法的请求。这是可能的，比如服务器需要临时禁止对资源的任何访问。

16. Authorization：请求消息头含有服务器用于验证用户代理身份的凭证，通常会在服务器返回[`401`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/401) `Unauthorized` 状态码以及[`WWW-Authenticate`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/WWW-Authenticate) 消息头之后在后续请求中发送此消息头。

17. Cache-Control：用于http请求和响应中通过指定指令来实现缓存机制。缓存指令是单向的，意味着在请求设置的指令，在响应中不一定包含相同的指令。

- 缓存请求指令

  ```
  Cache-Control: max-age=<seconds>(最大存储周期，相对于请求的时间)
  Cache-Control: max-stale[=<seconds>](表明客户端愿意接收一个已经过期的资源。 可选的设置一个时间(单位秒)，表示响应不能超过的过时时间)
  Cache-Control: min-fresh=<seconds>(表示客户端希望在指定的时间内获取最新的响应)
  Cache-control: no-cache 
  Cache-control: no-store
  Cache-control: no-transform
  Cache-control: only-if-cached(表明客户端只接受已缓存的响应，并且不要向原始服务器检查是否有更新的拷贝)
  ```

- 缓存响应指令

  ```
  Cache-control: must-revalidate(缓存必须在使用之前验证旧资源的状态，并且不可使用过期资源)
  Cache-control: no-cache(在释放缓存副本之前，强制告诉缓存将请求提交给原始服务器进行验证)
  Cache-control: no-store(缓存不应存储有关客户端请求或服务器响应的任何内容)
  Cache-control: no-transform(不得对资源进行转换或转变)
  Cache-control: public(可缓存，表明响应可以被任何对象缓存)
  Cache-control: private(可缓存，表明响应只能被单个用户缓存，不能作为共享缓存，即代理服务器不能缓存)
  Cache-control: proxy-revalidate(与must-revalidate作用相同，但它仅适用于共享缓存（例如代理），并被私有缓存忽略)
  Cache-Control: max-age=<seconds>
  Cache-control: s-maxage=<seconds>(覆盖max-age 或者 Expires 头，但是仅适用于共享缓存(比如各个代理)，并且私有缓存中它被忽略。)
  ```

- 拓展Cache-Control指令

  ```
  Cache-control: immutable (表示响应正文不会随时间而改变)
  Cache-control: stale-while-revalidate=<seconds>(表明客户端愿意接受陈旧的响应，同时在后台异步检查新的响应。秒值指示客户愿意接受陈旧响应的时间长度)
  Cache-control: stale-if-error=<seconds>(表示如果新的检查失败，则客户愿意接受陈旧的响应。秒数值表示客户在初始到期后愿意接受陈旧响应的时间)
  ```

禁止缓存

```
Cache-Control: no-cache, no-store, must-revalidate
```

缓存静态资源

```
Cache-Control: public, max-age=31536000
```

18. Clear-Site-Data：表示清除当前请求网站有关的浏览器数据（cookie，存储，缓存）。若想清楚所有类型的数据，可以使用通配符（*）

```
// 单个参数
Clear-Site-Data: "cache"
// 多个参数(用逗号分隔)
Clear-Site-Data: "cache", "cookies"
```

参数：

- "cache" 服务端希望删除本URL原始响应的本地缓存数据。根据浏览器不同，可能还会清除预渲染页面，脚本缓存，WebGL着色器缓存或者地址栏建议等内容
- "cookies"服务端希望删除URL响应的所有cookie。HTTP身份验证凭据也会被清除
- "storage"服务端希望删除URL原响应的所有DOM存储，包括存储机制，如localStorage、sessionStorage、IndexedDB、服务注册线程、AppCache、WebSQL数据库、FileSystem API data、Plugin data
- "executionContexts" 服务端希望浏览器重新加载本请求（location.reload）
- "*" 服务端希望清除原请求响应的所有类型的数据

**登出**，如果用户退出网站或服务，希望删除本地存储的数据。可以在https://example.com/logout的**响应头**增加Clear-Site-Data

```
Clear-Site-Data: "cache", "cookies", "storage", "executionContexts"
```

清除cookies，如果在https://example.com/clear-cookies的响应头中出现，则同一域和所有子域（如https://stage.example.com等）的所有Cookie，都会被清除

```
Clear-Site-Data: "cookies"
```

19. Connection：决定当前的事务完成后，是否会关闭网络连接。如果该值是“keep-alive”，网络连接就是持久不会关闭的。keep-alive不是必须填的

20. Content-Disposition：指示回复的内容该以何种形式展示，以内联（**inline**）即网页或者页面的一部分，还是附件（attachment）的形式下载并保存到本地，大多数浏览器会呈现一个“保存为”的对话框，将filename的值预填为下载后的文件名

Content-Disposition: inline

Content-Disposition: attachment

Content-Disposition: attachment; filename="filename.jpg"

21. Content-Encoding：实体消息首部，用于对特定媒体类型的数据进行压缩。对于特定类型的文件，比如jpeg图片文件，已经进行压缩过的，就不需要继续压缩

22. Content-Language：用来说明访问者希望采用的语言或语言组合，这样的话用户就可以根据自己偏好的语言来定制不同的内容

23. Content-Length：用来指名发送给接收方的消息主体的大小，用十进制数字表示

24. Content-Location：首部指定的是要返回的数据的地址选项。最主要的用途是用来指定要访问的资源经过内容协商后的结果的URL

**Location**-指定的是一个重定向请求的目的地址（或者新创建的文件的URL）-对应的是响应

Content-Location-指向的是可供访问的资源的直接地址，不需要进行进一步的内容协商-对应的是要返回的实体

25. Content-Range：显示的是一个数据片段在整个文件中的位置

Content-Range: <**unit**>  <**range-start**>-<**range-end**>/<**size**>

Content-Range: <**unit**>  <**range-start**>-<**range-end**>/*

Content-Range: <**unit**>  */<**size**>

unit-数据区间所采用的单位。通常是字节（byte）

range-start-区间起始值

range-end-区间的结束值

size-整个文件的大小

26. Content-Security-Policy：允许站点管理者在指定的页面控制用户代理的资源。主要以白名单的形式配置可信任的内容来源，在网页中，能够使用白名单中的内容正常执行（包含JS、CSS、Image等），而非白名单的内容无法正常执行，这条策略将极大的指定服务源以及脚本端点。减少**跨站点脚本攻击（XSS）**，也能减少**运营商劫持的内容注入攻击**

Head中添加Meta标签示例

```
<meta http-equiv="Content-Security-Policy" content="script-src 'self'">
```

不支持CSP的浏览器将会自动忽略CSP的信息，不会有什么影响

当定义多个策略的时候，浏览器会优先采用最先定义的。

| 指令            | 取值示例                  | 说明                                                         |
| --------------- | ------------------------- | ------------------------------------------------------------ |
| default-src     | 'self' cdn.example.com    | 定义针对所有类型（js/image/css/web font/ajax/iframe/多媒体等）资源的默认加载策略，某类型资源如果没有单独定义策略，就使用默认。 |
| script-src      | 'self' js.example.com     | 定义针对JavaScript的加载策略                                 |
| object-src      | 'self'                    | 针对,, 等标签的加载策略                                      |
| style-src       | 'self' css.example.com    | 定义针对样式的加载策略                                       |
| img-src         | 'self' image.example.com  | 定义针对图片的加载策略                                       |
| media-src       | 'media.example.com'       | 针对或者引入的html多媒体等标签的加载策略                     |
| frame-src       | 'self'                    | 针对iframe的加载策略                                         |
| connect-src     | 'self'                    | 针对Ajax、WebSocket等请求的加载策略。不允许的情况下，浏览器会模拟一个状态为400的响应 |
| font-src        | font.qq.com               | 针对Web Font的加载策略                                       |
| sandbox         | allow-forms allow-scripts | 对请求的资源启用sandbox                                      |
| report-uri      | /some-report-uri          | 告诉浏览器如果请求的资源不被策略允许时，往哪个地址提交日志信息。不阻止任何内容，可以改用Content-Security-Policy-Report-Only头 |
| base-uri        | 'self'                    | 限制当前页面的url（CSP2）                                    |
| child-src       | 'self'                    | 限制子窗口的源(iframe、弹窗等),取代frame-src（CSP2）         |
| form-action     | 'self'                    | 限制表单能够提交到的源（CSP2）                               |
| frame-ancestors | 'none'                    | 限制了当前页面可以被哪些页面以iframe,frame,object等方式加载（CSP2） |
| plugin-types    | application/pdf           | 限制插件的类型（CSP2）                                       |
| manitest-src    |                           | 限制application manifest文件源                               |
| worker-src      |                           | 限制Worker，SharedWorker或者ServiceWorker脚本源              |
| disown-opener   |                           | 确保资源在操作的时候能够脱离父页面                           |
| navigation-to   |                           | 限制文档可以通过以下任何方式访问URL（a，form，window.location，window.open，etc） |
| report-to       |                           | Fires a `SecurityPolicyViolationEvent`                       |

指令值示例及说明

| 指令值                              | 示例                                        | 说明                                                         |
| ----------------------------------- | ------------------------------------------- | ------------------------------------------------------------ |
| *                                   | img-src *                                   | 允许任何内容                                                 |
| none'                               | img-src 'none'                              | 不允许任何内容                                               |
| 'self'                              | img-src 'self'                              | 允许同源内容                                                 |
| data:                               | img-src data:                               | 允许data:协议（如base64编码的图片）                          |
| [www.a.com](http://www.a.com/)      | img-src [www.a.com](http://www.a.com/)      | 允许加载指定域名的资源                                       |
| *.a.com                             | img-src *.a.com                             | 允许加载a.com任何子域的资源                                  |
| [https://img.com](https://img.com/) | img-src [https://img.com](https://img.com/) | 允许加载img.com的https资源                                   |
| https:                              | img-src https:                              | 允许加载https资源                                            |
| 'unsafe-inline'                     | script-src 'unsafe-inline'                  | 允许加载inline资源（style属性，onclick，inline js和inline css等等） |
| 'unsafe-eval'                       | script-src 'unsafe-eval'                    | 允许加载动态js代码，例如eval()                               |

CSP使用方式

HTML Meta标签

Meta标签主要含有两部分的key-value：

- http-equiv
- content

```
<meta http-equiv="Content-Security-Policy" content="script-src 'self'">
```

HTTP Header

通过HTTP header带上CSP的指令，可以支持所有请求

```
Content-Security-Policy: script-src 'self' *.qq.com *.url.cn
```

27. Content-Security-Policy-Report-Only：响应头允许通过监测策略，生成JSON文档，通过POST请求发送到指定的URI，该策略只会返回报告，不会阻止运行，这是和Content-Security-Policy的却别

28. Content-Type：用于指示资源的MIME类型media type。在响应中，Content-Type标头告诉客户端实际返回的内容的内容类型。浏览器会在某些情况下进行MIME查找，并不一定遵循此标题的值；为了防止这种行为，可以将标题**X-Content-Type-Options**设置为**nosniff**

29. Cookie：存放由服务端通过Set-Cookie设置的HTTP cookies

30. DNT（Do Not Track）：表明用户对于网站追踪的偏好。DNT: 0/1

0-表示用户愿意目标站点追踪用户个人信息

1-表示用户不愿意目标站点追踪用户个人信息

31. Date：包含了消息生成的日期和时间

32. Etag：资源的特定版本的标识符。让缓存更高效，并节省带宽，如果内容没有改变，Web服务器不需要发送完整的响应。Etag可以防止资源的同时更新相互覆盖（“空中碰撞”）

如果给定URL中的资源更改，则一定要生成新的Etag值。比较etags能快速确定此资源是否变化，但也可能被跟踪服务器永久存留。

指令

- 'W/'表示使用弱验证器。弱验证器很容易生成，但不利于比较
- "<**etag-value**>"实体标签唯一表示所请求的资源。没有明确的算法实现，通常可以使用内容的散列，最后修改时间戳的哈希值，或简单的使用版本号方式

**避免“空中碰撞”**- 使用Etag和If-Match头部实现

**缓存未更改的资源**-通过Etag和If-None-Match比较实现。1.用户再次访问给定的URL（设有ETag字段），显示资源过期了且不可用，客户端就发送值为ETag的IF-None-Match header字段 2.服务端将客户端的ETag与其当前版本的资源的ETag进行比较，如果两个值匹配，服务器将返回不带任何内容的304未修改状态，告诉客户端缓存版本可用

33. Expect：是一个请求消息头，包含一个期望条件，表示服务器只有在满足此期望条件的情况下才能妥善处理请求。

34. Expires：响应头包含日期/时间，即在此时候之后，响应过期（http1.1）

如果在Cache-Control响应头中设置了"max-age"或者"s-max-age"指令，那么Expires头会被忽略

35. Forwarded：包含了代理服务器的客户端的信息，即由于代理服务在请求路径中的接入而被修改或丢失的信息。可以用X-Forwarded-For、X-Forwarded-Host、X-Forwarded-Proto替换。会暴露一定的隐私和敏感信息，比如客户端的IP地址。

```
Forwarded: by=<identifier>; for=<identifier>; host=<host>; proto=<http|https>
```

Identifier - 显示在使用代理的过程中被修改或者丢失的信息。

- 一个IP地址（V4或V6，ipv6地址需要包含在方括号里面，同时用括号括起来）
- 语意不明的标识符（比如“_ hidden”或“_ secret”）
- "unknown"，当前信息实体不可知

by - 请求进入到代理服务器的接口

for - 发起请求的客户端以及代理链中的一系列的代理服务器

host - 代理接收到的Host首部的信息

proto - 发起请求时采用的何种协议，通常是"http"或者"https"

```
# 大小写不敏感
Forwarded: For="[2001:db8:cafe::17]:4711"

# for proto by 之间可用分号分隔
Forwarded: for=192.0.2.60; proto=http; by=203.0.113.43

# 多值可用逗号分隔
Forwarded: for=192.0.2.43, for=198.51.100.17
```

36. Host：指名了服务器的域名，以及（可选的）服务器监听的TCP端口号。如果没有给定端口号，会自动使用被请求服务的默认端口（一般为80）HTTP1.1的所有请求报文中**必须包含**一个Host头字段。如果一个HTTP1.1请求缺少Host头字段或者设置了超过一个的Host头字段，会返回400状态码

37. If-Match：表示是一个条件请求。在请求方法为GET和HEAD的情况下，服务器仅在请求的资源满足此首部列出的ETag之一时才会返回资源。而对于PUT或其他非安全方法来说，只有在满足条件的情况下才可以将资源上传

38. If-Modified-Since：条件式请求首部，服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为200。如果请求的资源从那时未修改，那么返回一个不带有消息主体的304响应，而在**Last-Modified**首部中会带有上次修改时间。该**请求参数只会在GET或者HEAD请求中使用**

当与If-None-Match一同出现时，会被忽略掉，除非服务器不支持If-None-Match

39. If-None-Match：表示是一个条件请求。对于GET和HEAD请求方法，当且仅当服务器上没有任何资源的ETag属性值与这个首部中列出的相匹配的时候，服务器端才会返回请求的资源，响应码200。对于其他方法来说，当且仅当最终确认没有已存在的资源的  [`ETag`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/ETag) 属性值与这个首部中所列出的相匹配的时候，才会对请求进行相应的处理。

40. If-Range：HTTP请求头字段用来使得Range头字段在一定条件下起作用：当字段值中的条件得到满足时，Range头字段才会起作用，同时服务器回复**206**部分内容状态码，以及Range头字段请求的响应部分；如果字段值中的条件没有得到满足，服务器将会返回200状态码，将返回完整的请求资源

If-Range头字段通常用于断点续传的下载过程中，用来自从上次中断后，确保下载的资源没有发生改变

```
If-Range: <星期>, <日> <月> <年> <时>:<分>:<秒> GMT
If-Range: <etag>
```

41. If-Unmodified-Since：用于请求中，使得当前请求称为条件式请求：只有当资源在指定的时间之后没有进行过修改的情况下，服务器才会返回请求的资源，或是接受POST或其他non-safe方法的请求。如果所请求的资源在指定的时间之后发生了修改，那么会返回412错误

应用场景：

- 与non-safe方式如POST搭配使用，可以用来优化并发控制
- 与含有If-Range消息头的范围请求搭配使用，用来确保新的请求片段来自于未经修改的文档

42. Keep-Alive（非标准）：允许消息发送者暗示连接的状态，还可以用来设置超时时长和最大请求数

43. Large-Allocation(非标准)：用来告诉浏览器加载该页面可能需要申请大内存。当前只有Firefox实现。WebAssembly或者asm.js会使用比较大的连续内存空间。Large-Allocation告诉浏览器将要加载的页面可能需要申请一个大的连续内存空间，浏览器依据该头部可能会单独启动一个专有的进程用于处理该页面

指令：0- 是一个特殊值，代表分配的大小不确定（动态允许） <**megabytes**>- 预期需要申请的内存大小，以M为单位

44, Last-Modified：响应首部，包含源头服务器认定的资源作出修改的日期及时间。

45. Location：首部指定的是需要将页面重新定向至的地址（状态码为303、307、308、301、302）或者新创建的文件的URL（状态为201）。一般在响应码为3XX的响应中才会有意义

46. Origin：请求首部，指示请求来自于哪个站点。该字段指示服务器名称，并不包含任何路径信息。该首部用于**POST**或者**CORS**请求

47. Proxy-Authenticate：响应首部，指定了获取proxy server（代理服务器）上的资源访问权限而采用的身份验证方式。代理服务器对请求进行验证，以便进一步传递请求。

48. Proxy-Authentization：请求首部，其中包含了用户代理提供给代理服务器的用于身份验证的凭证

49. Range：请求首部，告知服务器返回文件的哪一部分。在一个Range首部中，可以一次性请求多个部分，服务器会以multipart文件的形式将其返回。如果服务器返回的是范围响应，需要使用206状态码。

```
Range: <unit>=<range-start>-
Range: <unit>=<range-start>-<range-end>
Range: <unit>=<range-start>-<range-end>, <range-start>-<range-end>
Range: <unit>=<range-start>-<range-end>, <range-start>-<range-end>, <range-start>-<range-end>
```

50. Referer：包含了当前请求页面的来源页面的地址，即表示当前页面是通过此来源页面里的链接进入的。服务端一般用该首部识别访问来源。

```
Referer首部可能暴露用户的浏览历史，涉及到用户的隐私问题
```

在以下两种情况下，Referer不会被发送：

- 来源页面采用的协议为表示本地文件的 "file" 或者 "data" URI；
- 当前请求页面采用的是非安全协议，而来源页面采用的是安全协议（HTTPS）

51. Referrer-Policy：用来监管哪些访问来源信息—会在Referer中发送—应该被包含在生成的请求当中

指令：

- no-referrer- 整个referer首部会被移除
- no-referrer-when-downgrade（默认值）- 在没有指定任何策略的情况下用户代理的默认行为。在同等安全级别的情况下，引用页面的地址会被发送（HTTPS -> HTTPS），但是在降级的情况下不会被发送（HTTPS->HTTP）
- origin- 在任何情况下，仅发送**文件的源**作为引用地址
- origin-when-cross-origin- 对于**同源的请求**，会发送**完整的URL**作为引用地址，但是对于**非同源请求**仅发送**文件的源**
- same-origin- 对于同源的请求会发送引用地址，非同源不会发送
- strict-origin- 在同等安全级别的情况下，发送文件的源作为引用地址，降级的情况不会发送
- strict-origin-when-cross-origin- 对于同源的请求，会发送完整的URL作为引用地址；在同等安全级别的情况下，发送文件的源作为引用地址；在降级的情况下不发送此首部
- unsafe-url- 无论是同源请求还是非同源请求，都发送完整的URL作为引用地址

例子[https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Referrer-Policy](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Referrer-Policy)

52. Retry-After：响应首部，表示用户代理需要等待多长时间之后才能继续发送请求

- 当与503（当前服务不存在）响应一起发送的时候，表示服务下线的预期时长
- 当与重定向响应一起发送的时候，如301（永久迁移），表示用户代理在发送重定向请求之前需要等待的最短时间

53. Set-Cookie：响应首部，被用来由服务器向客户端发送cookie

指令：

**Expires**=<**date**> cookie的最长有效时间，形式为符合HTTP-date规范的时间戳。如果没有设置这个属性，表示是一个**会话期cookie**

**Max-Age**=<**non-zero-digit**> 在cookie失效之前需要经过的秒数。老的浏览器（ie6 7 8）不支持这个属性。Expires和Max-Age同时存在，Max-Age优先级更高

**Domain**=<**domain-value** > 指定cookie可以送达的主机名

**Path**=<**path-value**> 指定一个URL路径，这个路径必须出现在要请求的资源的路径中才可以发送Cookie首部。如果path=/docs，那么"/docs"，"/docs/Web/"或者"/docs/Web/HTTP"都满足匹配的条件

**Secure** 只有在请求使用SSL和HTTPS协议的时候才会被发送到服务器

**HttpOnly** 设置了HttpOnly属性的cookie不能使用Javascript经由Document.cookie属性、XMLHttpRequest和Request API上进行访问，防范跨站脚本攻击（XSS）

**SameSite**=**Strict/Lax** 设置后cookie不随跨域请求一起发送，一定程度上防范跨站请求伪造攻击（CSRF）

54. SourceMap HTTP响应头连接生成的代码到一个source map，使浏览器能够重建原始的资源然后显示在调试器里

55. User-Agent 首部包含了一个特征字符串，用来让网络协议的对端来识别发起请求的用户代理软件的应用类型、操作系统、软件开发商以及版本号

```
User-Agent: <product> / <product-version> <comment>
```

```
Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0
Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0
```

56. Vary 响应头，决定了对于未来的一个请求头，应该用一个缓存的回复（response）还是向源服务器请求一个新的回复

## HTTP权威指南

### 概述

Web服务器是Web资源(Web resource)的宿主。Web资源是Web内容的源头。最简单的Web资源就是Web服务器文件系统中的静态文件。还可以包含：文本文件、HTML文件、微软的Word文件、Adobe的Acrobat文件、JPEG图片文件、AVI电影文件，或所有其他能够想到的格式。

#### URI

服务器资源名被称为统一资源标识符（Uniform Resource Identifier, URI）。URI有两种方式，分别称为URL和URN

#### URL

**统一资源定位符(URL)**是资源标识符最常见的形式。URL描述了一台特定服务器上某资源的特定位置。

大多数URL方案的URL语法都建立在由9部分构成的通用格式上：

```
<scheme>://<user>@<password>:<host>:<port>/<path>;<params>?<query>#<frag>
```

但最重要的3个部分是**方案(scheme)**，**主机(host)**，**路径(path)**

**参数(params)**：某些方案会用这个组件来指定输入参数。参数为键/值对。URL中可以包含多个参数字段，它们相互之间以及与路径的其余部分之间用分号(;)分隔

**片段(frag)**：引用对象时，不会将frag字段传送给服务器；这个字段是在客户端内部使用的。通过字符"#"将其与URL的其余部分分隔开来

#### URN

**统一资源名(URN)**是作为特定内容的唯一名称使用的，与目前的资源所在地无关。通过URN，还可以用同一个名字通过多种网络访问协议来访问资源。

### 事务

一个HTTP事务由一条（从客户端发往服务器的）请求命令和一个（从服务器发回客户端的）响应结果组成。这种通信是通过名为HTTP报文（HTTP message）的格式化数据块进行的。

### 报文

HTTP报文是由一行一行的简单字符串组成的。HTTP报文都是纯文本，不是二进制代码。

HTTP报文包括三个部分：

- 起始行

  报文的第一行就是起始行，在请求报文中用来说明要做什么，在响应报文中说明出现了什么情况

- 首部字段

  起始行后面有零个或多个首部字段。首部以一个空行结束。

- 主体

  空行之后就是可选的报文主体，其中包含了所有类型的数据。**请求主体中包括了要发送给Web服务器的数据；响应主体中装载了要返回给客户端的数据。**主体中可以包含任意的二进制数据(比如图片、视频、音轨、软件程序)。

### Web的结构组件

#### 代理

HTTP代理服务器，这是Web安全、应用集成以及性能优化的重要组成模块。

出于安全考虑，通常会将代理作为转发所有Web流量的可信任中间节点使用。代理还可以对请求和响应进行过滤。

#### 缓存

Web缓存(Web cache)是一种特殊的HTTP代理服务器，可以将经过代理传送的常用文档复制保存起来。

#### 网关

网关(gateway)是一种特殊的服务器，**作为其他服务器的中间实体使用**。通常用于将HTTP流量转换成其他的协议。网关接收请求时就好像自己是资源的源端服务器一样。

#### 隧道

隧道(tunnel)是建立起来之后，就会在两条连接之间对原始数据进行盲转发的HTTP应用程序。HTTP隧道通常用来在一条或多条HTTP连接上转发非HTTP数据，转发时不会窥探数据。

HTTP隧道的一种常见用途是通过HTTP连接承载加密的安全套接字层(SSL)流量，这样SSL流量就可以穿过只允许Web流量通过的防火墙了。

#### Agent代理

用户Agent代理(或者简称为Agent代理)是代表用户发起HTTP请求的客户端程序。所有发布Web请求的应用程序都是HTTP Agent代理。比较常说到的HTTP Agent代理是Web浏览器。但除了这个，还有些自动用户Agent代理，比如"网络蜘蛛"(spiders)或者"Web机器人"(Web robots)。

### URL与资源

#### URL编码

为了避开安全字符集表示法带来限制，设计了一种编码机制，用来在URL中表示各种不安全的字符。这种编码机制就是通过一种"转义"表示法来表示不安全字符的，这种转义表示法包含一个百分号(%)，后面跟着两个表示字符ASCII码的十六进制数。

在URL中，有几个字符被保留起来，有着特殊的含义。在将其用于保留用途之外的场合时，要在URL中对其进行编码。包括：

- % - 保留作为编码字符的转义字符
- / - 保留作为路径组件中分隔路径段的定界符
- . - 保留在路径组件中使用
- .. - 保留在路径组件中使用
- \# - 保留作为分段定界符使用
- ? - 保留作为查询字符串定界符使用
- ; - 保留作为参数定界符使用
- : - 保留作为方案、用户/口令，以及主机/端口组件的定界符使用
- $,+ - 保留
- @ & = - 在某些方案的上下文中有特殊的含义，保留
- { } | \ ^ ~ [ ] ' - 由于各种传输Agent代理，比如各种网关的不安全处理，使用受限
- < > " - 不安全
- 0x00-0x1F,0x7F - 受限这些十六进制范围内的字符都在US-ASCII字符集的不可打印区间内
- \> 0x7F - 受限，十六进制值不在US-ASCII字符集的7比特范围内

### HTTP报文

#### 报文流

**这是形容http报文的**

- http报文是以一种类似的流的方式来发送数据的，所以报文流讲述了http报文的一些客观状态，相关术语：流入、流出形容事务处理。http报文任何时候是从上游向下游流入的！其中进过的节点既可能是上游，有可能是下游，如果从某个节点流出，那么相对于此节点流入的那个节点，它就是上游，反过来它就是下游！

#### 报文的组成部分

每条报文都包含一条来自客户端的请求，或者一条来自服务器的响应。由三部分组成：起始行(start line)、包含属性的首部(header)块、以及可选的、包含数据的主体(body)部分。

每行都以一个由两个字符组成的行终止序列作为结束，其中包括一个回车符和一个换行符，写做**CRLF**。

http报文分为请求报文和相应报文，其语法分别如下：

```
//请求报文

<method> <request-URL> <version>
<headers>

<entity-body>

//响应报文

<version> <status> <reason-phrase>
<headers>

<entity-body>
```

```
方法是客户端希望执行的动作，如GET、POST等

请求url是指请求资源的路径

http版本号，格式为http/<major>.<minor>,分别代表主要版本号和次要版本号，其含义应分开理解

status code其实说白了就是用一个数字表示当前事务处于什么状态，便于开发者处理

原因短语，实际意义不大，就是为了方便人看的

首部就是一个包含零个或多个的键值对，键值对以crlf隔开，而键、值之间以‘:’隔开，期间包含一个可选的空格

主体任意格式组成的数据块，也是实际发送的内容
```

##### 方法

- GET方法用于请求服务器端发送某个资源
- HEAD方法跟GET方法类似，区别就是不返回主体
- PUT方法用于向服务器端修改、插入数据
- POST方法用于向服务器端发送数据
- TRACK方法用于向服务器端请求报文在发送的过程中经过了什么修改，主要用于测试
- OPTIONS用于请求服务器告知其支持什么功能
- DELETE用于向服务器删除某个指定的资源
- 扩展方法其实类似于自定义方法

##### 状态码

- 100-199 信息性状态码
- 200-299 成功状态码 （常见200表示请求成功）
- 300-399 重定向状态码 （常见302重定向）
- 400-499 客户端错误状态码 （常见404，请求资源不存在）
- 500-599 服务端错误状态码

### 连接管理

> TCP/IP的一些知识：TCP/IP建立连接会做哪些事情，带来的时延。提升性能的方法，包括串行连接、并行连接、持久链接、管道连接等。

#### TCP连接

客户端应用程序可以打开一条TCP/IP连接，连接到可能运行在任何地方的服务器应用程序。一旦连接建立起来，在客户端和服务器的计算机之间交换的报文就永远不会丢失、受损或失序。

**当键入一个URL时，HTTP会发生哪些事情？**

1. 浏览器从地址栏中解析处域名（主机名），也就是拿到www.xxx.com
2. 浏览器根据得到的主机名查询出ip地址，如x.x.x.x，（中间可能经过查找host文件或去查询dns服务器）
3. 浏览器解析出端口（http默认为80，https默认为443）
4. 浏览器发起一条到x.x.x.x端口为80的链接，（重建需要经过几次确定相关参数的来回“握手”）
5. 浏览器发起请求报文
6. 服务器返回响应报文
7. 浏览器关闭连接（其实浏览器和服务器都可以在不通知对方的情况关闭连接）

TCP的数据是通过名为IP分组(或IP数据报)的小数据块来发送的。HTTP要传送一条报文时，会以留的形式将报文数据的内容通过一条打开的TCP连接按序传输。TCP收到数据流之后，会将数据流分成被称作段的小数据块，并将段封装在IP分组中，通过因特网进行传输。

每个IP分组中都包括：

- 一个IP分组首部(通常为20字节)
- 一个TCP段首部(通常为20字节)
- 一个TCP数据块(0个或多个字节)

TCP是通过端口号来保持所有这些连接持续不断地运行。

TCP用四个信息来唯一确定一条连接：源ip地址、源端口号、目的ip地址、目的端口号。只要其中有一个不同，那么就不是同一条连接。在任意时刻计算机都可以有几条tcp连接在打开状态。

TCP编程接口，提供了一套完整的套接字API。向HTTP程序员隐藏了TCP和IP的所有细节。套接字API允许用户创建TCP的端点数据结构，将这些端点与远程服务器的TCP端点进行连接，并对数据流进行读写。

#### 对TCP性能的考虑

与建立TCP连接，以及传输请求和响应报文的时间相比，事务处理时间可能是很短的。除非客户端或服务器超载，或正在处理复杂的动态资源，否则HTTP时延就是由TCP网络时延构成的。

HTTP事务的时延主要原因：

1. 首先客户端解析ip地址或者端口号需要时间，如果当前没有访问过相关资源，那么解析还需要查询dns服务器，此操作，造成的时延较多，可能花费数十秒。
2. 建立tcp链接会有建立时延，通常2s左右，如果当前的http事务较多，那么会很快叠加上去。
3. 传输、处理请求报文需要时间
4. 回传响应报文需要时间
5. 当然还有其他因素，比如硬件、网络负载，以及报文尺寸等！

TCP相关时延其中包括：

- TCP连接建立握手

- TCP慢启动拥塞控制

- 数据聚集的Nagle算法

  Nagle算法试图在发送一个分组之前，将大量TCP数据绑定在一起，以提高网络效率。该算法鼓励发送全尺寸(LAN上最大尺寸的分组大约是**1500字节**)的段。但该算法会带来几个HTTP性能问题：小的HTTP报文可能无法填满一个分组，可能会因为等待那些永远不会到来的额外数据而产生时延。Nagle算法与延迟确认之间的交互存在问题—Nagle算法会阻止数据的发送，直到有确认分组抵达为止，但确认分组自身会被延迟确认算法延迟100-200毫秒。

  一般设置**TCP_NODELEY**，禁用Nagle算法提高性能

- 用于捎带确认的TCP延迟确认算法

  每个TCP端都有一个序列号和数据完整性校验和。每个段的接受者收到完好的段时，都会向发送者回送小的确认分组。由于确认报文很小，所有TCP允许在发往相同方向的输出数据分组中对其进行"捎带"。为了增加确认报文找到同向传输数据分组的可能性，很多TCP栈都实现了一种"延迟算法"。会在一个特定的窗口时间(通常是100-200毫秒)内将输出确认存放在缓冲区中，以寻找能够捎带它的输出数据分组。如果在那个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送

- TIME_WAIT时延和端口耗尽

  当某个TCP端口关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近所关闭连接的IP地址和端口号。通常是所估计的最大分段使用期的两倍。**这个算法可以防止在两分钟内创建、关闭并重新创建两个具有相同IP地址和端口号的链接。**

#### HTTP连接的处理

##### Connection

两个相邻的HTTP应用程序可以共享只需要他们二者的选项，可以通过Connection来传递，这个首部字段可以通过逗号分隔传递连接标签列表，并且这些标签不会传播到其他连接中去，会在这个连接中就删除。除了Connection首部有这个特性以外，还包括Proxy-Authenticate、Proxy-Connection、Transfer-Encoding和Upgrade。

Connection首部可以承载三种字段值：

- HTTP首部字段名(如Keep-Alive)，列出了只与此连接有关的首部
- 任意标签值，用于描述此连接的非标准选项
- 值close，说明操作完成之后需关闭这条持久连接

##### 串行连接

此种机制描述了http事务一个一个接着发起，不能同时下载更多的资源，使得界面上用户看不到东西，体验不够好。串行连接没有很好的利用tcp/ip连接的慢启动机制！

优化方法：

- 并行连接

  浏览同时发起过个http事务，因为是并行的，所以时延也并行的，这样总时延较小，页面呈现更快，体验较好。但也不是总是这样，因为如果在网络速度很慢的时候，多个连接会去竞争本来不多的带宽，那么就谈不上加快速度了。还有就是并行连接也是需要付出代价的，比如增加系统内训消耗、服务器负载，比如有一个100客户端同时对服务发起100tcp并行连接的话，那么服务器就得负责10000个处理请求，很快的你的服务器就会爆掉。当然了，并行连接确实能带来视觉上的速度提升，因为相比于串行连接慢慢地显示数据而并行一下子能全部显示完信息，视觉上并行连接会给人速度更快的感觉。

  浏览器使用了并行连接，但他们会将并行连接的总数限制为一个较小的值（**通常是6个**）。

- 持久连接

  包括两种情况：

  - HTTP/1.0+ keep-alive连接

    客户端需要在链接中包含Connection: Keep-Alive首部请求，将连接保持在打开状态。此时服务器在响应中也会包含相同的首部。**如果响应中没有Connection: Keep-Alive首部，客户端就认为服务器不支持keep-alive，会在响应报文之后关闭连接**。

    当设置完Connection: Keep-Alive首部之后，可以设置Keep-Alive选项的值：

    - timeout - 估计服务器希望将连接保持在活跃状态的时间，但不是承诺值
    - max - 估计服务器希望为多少个事务保持此连接的活跃状态，但不是承诺值
    - 任意未经处理的属性，主要用于诊断和调试，语法为name [=value]

    **Keep-Alive和哑代理会产生一些特殊的问题！**哑代理只会盲目的转发客户端发送的请求中的所有首部，不会去除connection首部，导致服务器返回带有connection: Keep-Alive首部给客户端，服务器不会关闭连接，代理始终被挂起等待关闭，客户端发送新的请求，代理不认请求，导致被忽略，直至超时，并将其关闭为止。

    使用**Proxy-Connection: Keep-Alive解决客户端和服务端之间只有一个代理的情况的哑代理问题**。哑代理不会识别Proxy-Connection，但Connection没有设置，所以不会有问题；能识别Proxy-Connection的代理，会把Proxy-Connection的值赋给Connection，使得在传输过程中不会关闭连接。但对于大于一个代理的情况又变得没有意义了。

  - HTTP/1.1 persistent连接

    默认情况下是激活的。可以通过显示的添加Connection: close关闭连接。但是不发送这个首部也是可以关闭的。

- 管道化连接

  HTTP1.1允许在持久连接上可选地使用请求管道。在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向另一端的服务器时，第二条和第三条请求也可以开始发送。

- 复用的连接

#### 关闭连接的奥秘

所有HTTP客户端、服务器或代理都可以任意时刻关闭一条TCP传输连接。

HTTP响应都应该有精确的Content-Length首部，用以描述响应主体的尺寸。如果在响应关闭结束时，实际传输的实体长度与Content-Length并不匹配(或没有Content-Length)时，接收端就应该质疑。

如果接收端是缓存代理，接收端不能缓存不匹配的响应。

如果一个事务、不管是执行一次还是很多次，得到的结果都是相同，这个事务就是幂等的。GET、HEAD、PUT、DELETE、TRACE和OPTIONS都具有这个特性。客户端不应该以管道化方式传送非幂等请求（比如POST）。

关闭分两种：

- 完全关闭 - 套接字调用close()会将TCP连接的输入和输出信道都关闭
- 半关闭 - 套接字调用shutdown()会单独关闭输入或输出信道

关闭连接是有学问的。

**关闭连接的输出信道总是安全的**。连接的另一端的对等实体会在从器缓冲区中读出所有数据之后收到一条通知，说明流结束了，这样它就知道将连接关闭了。

**关闭连接的输入信道比较危险**。如果另一端向你已关闭的输入信道发送数据，操作系统就会向另一端机器回送一条TCP"连接被对端重置"的报文，会导致的问题比较严重，即删除对端还未读取的所有缓存数据。例如，传输了10条请求都已经接收到缓存中，但第11条因为关闭了输入信道，导致前面的10条缓存都被删除。

总之，实现正常关闭的应用程序首先应该关闭它们的输出信道，然后等待连接另一端的对等实体关闭它的输出信道。当两端都告诉对方它们不会再发送任何数据(比如关闭输出信道)之后，连接就会被完全关闭，而不会有重置的危险。

但也无法确保对等实体会实现半关闭，或对其进行检查。但是要关闭输出信道，然后周期性地检查其输入信道的状态(查找数据，或流的末尾)。如果在一定的时间区间内对端没有关闭输入信道，应用功能程序可以强制关闭连接，以节省资源。

### Web服务器

Web服务器实现了HTTP和相关的TCP连接处理。负责管理Web服务器提供的资源，以及对Web服务器的配置、控制及扩展方面的管理。

Web服务器逻辑实现了HTTP协议、管理着Web资源，并负责提供Web服务器的管理功能。Web服务器逻辑和操作系统共同负责管理TCP连接。底层操作系统负责管理底层计算机系统的硬件细节，并提供了TCP/IP网络支持、负责装载Web资源的文件系统以及控制当前计算活动的进程管理功能。

#### web服务器应该做些什么

1. 接受建立连接请求
2. 接受请求
3. 处理请求
4. 访问报文中指定的资源
5. 构建响应
6. 发送响应
7. 记录事务处理过程

#### 第一步————接受客户端连接

- 客户端收到一条连接之后，那么它将会把新连接添加到现存web服务器连接列表中，用于监视当前连接上的数据传输情况。
- 通过ident确认客户端用户。服务器可以通过ident协议**找到发起HTTP连接的用户名**。客户端如果支持ident协议，就在TCP端口113上接听ident请求。但ident在公共英特网上并不能很好的工作，因为：
  - 很多客户端PC没有运行ident识别协议守护进程软件
  - ident协议会使HTTP事务处理产生严重的时延
  - 防火墙不允许ident流量进入
  - ident协议不安全
  - ident不支持虚拟IP地址
  - 暴露客户端的用户名涉及隐私问题

#### 第二步————接收请求报文

- 主要经过几个步骤来解析报文：

1. 解析请求行，得知方法、url、协议版本，各项之间由一个空格分隔，并以回车换行(CRLF)序列作为行的结束
2. 解析得到以CRLF结尾的首部
3. 得到以CRLF结尾，标志首部结束的空行（如果有的话）
4. 解析得到主体（如果有的话）

- web服务可能还会把请求报文用一种自己能快速处理的内部数据结构来存储请求报文
- 不同的服务器配置预示它能同时处理的事务情况：

1. 单线程web服务器：只能处理一个请求，待当前请求处理完成之后才能处理下一个请求。优点：简单已于实现，适用于低负荷服务器。缺点：不能及时处理其他请求，容易引发延迟过长而导致性能问题。
2. 多线程及多进程web服务器：能同时处理多个请求。优点：响应及时。缺点：构建复杂，容易快速引起内存消耗过大而死机。最好应该对能同时处理的连接数量进行限制。
3. 复用i/o的web服务器：只有在有事情可做时才会对连接进行处理；在空闲连接上等待的时候并不会绑定线程和进程。
4. 复用i/o和多线程的web服务器：2和3的结合

#### 第三步————处理请求

#### 第四步————对资源的映射及访问

- 最简单的资源映射形式就是用请求URI作为名字来访问Web服务器文件系统中的文件。通常，Web服务器的文件系统中会有一个特殊的文件夹专门用于存放Web内容。这个文件夹被称为docroot(文档根目录)。但不能让相对URL退到docroot之外，将文件系统的其余部分暴露出来，也就是不允许访问根目录的上一级目录，如http://www.joes-hardware.com/../。
- 虚拟托管的docroot:在一个服务器上挂了几个web站点，那么这样当请求的资源路径相同时，服务器应该从请求报文首部的host、uri字段找出真正的资源目录，这些目录都是可以配置的。

#### 第五步————构建响应

- 构建响应报文：1、正确设置响应主体的长度（content-length）；2、设置报文的mime类型（content-type）,主要通过与一直mime类型文件匹配得到当前的文件的mime类型，还可以通过文件扩展名，以及硬规定特定目录下的文件拥有某个mime类型；3、控制重定向
- 服务器端如何得出文件的MIME类型：

```
Web服务器要负责确定响应主体的MIME类型。有很多配置服务器的方法可以将MIME类型与资源关联起来。

1、MIME类型（mime.types）
Web服务器可以用文件的扩展名来说明MIME类型。Web服务器会为每个资源扫描一个包含了所有扩展名的MIME类型的文件，以确定其MIME类型。这种基于扩展名的类型相关是最常见的！

2、魔法分类（Magic typing）
Apache Web服务器可以扫描每个资源的内容，并将其与一个已知模式表（被称为魔法文件）进行匹配，以决定每个文件的MIME类型。这样做可能比较慢，但很方便，尤其是文件没有标准扩展名的时候。

3、显示分类（Explicit typing）
可以对Web服务器进行配置，使其不考虑文件的扩展名或内容，强制特定文件或目录内容拥有某个MIME类型

4、类型协商
有些Web服务器经过配置，可以以多种文档格式来存储资源。在这种情况下，可以配置Web服务器，使其可以通过与用户的协商来是决定使用哪种格式（及相关的MIME类型）“最好”。
```

##### 重定向

- 有时服务器需要返回重定向报文来构建响应，重定向响应由返回码3XX说明。Location响应首部包含了内容的新地址或优选地址的URL。重定向可用于下列情况。
  - 永久删除的资源，状态码为301
  - 临时删除的资源，状态码为303或307
  - URL增强，状态码为303或307
  - 负载均衡，主要是减少服务器的压力，让请求跑到一个负载不大的服务器上去，状态码为303或307
  - 服务器关联，去保存有用户本地信息的服务器上获取用户信息，状态码为303或307
  - 规范目录名称，客户端请求的URI是一个不带尾部斜线的目录名时，大多数Web服务器都会将客户端重定向到一个加了斜线的URI上，这样相对链接就可以正常工作了！

#### 第六步————发送响应

#### 第七步————记录事务日志

- 在web服务器日志文件中添加一个条目，以描述当前事务处理情况

### 代理

Web代理(proxy)服务器是网络的中间实体。代理位于客户端和服务器之间，扮演"中间人"的角色，在各端点之间来回传送HTTP报文。HTTP的代理服务器既是Web服务器又是Web客户端。

代理服务器可以是某个客户端专用的，也可以是很多客户端共享的。单个客户端专用的代理被称为私有代理。众多客户端共享的代理被称为公共代理。

#### 代理与网关的对比

- 代理连接的是两个或多个使用相同协议的应用程序
- 网关连接的是两个或多个使用不同协议的端点，网关扮演的是"协议转换器"的角色，即使客户端和服务器使用的是不同的协议，客户端也可以通过它完成与服务器之间的事务处理

现在代理和网关之间的区别比较模糊。商业化的代理服务器也要实现网关的功能来实现SSL安全协议，SOCKS防火墙、FTP访问，以及基于Web的应用程序。

#### 为什么使用代理

- 改善安全性
- 提高性能
- 节省费用
- 可以看到并接触到所有流过的HTTP流量，可以监视流量并对其进行修改，以实现很多有用的增值Web服务
  - 儿童过滤器 - 如服务器响应的成人内容进行过滤
  - 文档访问控制 - 验证客户端访问某个的文件需要的证书
  - 安全防火墙 - 提供一个防火墙保护客户端或服务器
  - Web缓存 - 对客户端响应资源的副本，节省带宽、减少网络拥堵
  - 反向代理 - （原始服务的替代物，能访问其他服务器，作服务器加速器使用）伪装成原始服务器，不过与服务器不同的是反向代理还可以向其他服务器发送请求，以便实现按需定位所请求的内容
  - 内容路由器 - 根据因特网流量状况以及内容类型将请求导向特定的Web服务器
  - 转码器 - 可以修改内容的主体格式
  - 匿名者 - 主动从HTTP报文中删除身份特性（比如客户端IP地址、From首部、Referer首部、cookie、URI的会话ID），从而提供高度的私密性和匿名性

#### 代理服务器的部署

根据目标用途，可以将代理放在任意位置：

1. 出口代理：部署在本地网络端，用于保护本地网络或者限制公司带宽
2. 访问（入口）代理：用于实现提供缓存响应
3. 反向代理：通常被部署在网络边缘，在Web服务器之前，作为替代物使用。从而提高Web服务器安全特性，或者将快速的Web服务器缓存放在较慢的服务器之前，以提高性能
4. 网络交换代理：部署在网络上，通过缓存来减轻因特网节点的拥塞，并对流量进行监视

#### 代理如何获取流量

1. 修改客户端：比如现在的客户端都支持收手动和自动配置代理
2. 修改网络：网络通过一些技术在客户端不知情的情况揽入流量进入代理，这种代理被称为拦截代理
3. 修改DNS命名空间：把主机名映射为代理的ip地址，比如修改系统的DNS映射文件，让代理伪装成原始服务器，从而把web请求导入代理
4. 修改服务器：让服务器返回一个重定向有关的代码，把http请求报文导入到代理

#### 客户端代理设置

主要介绍客户端配置代理的几种常见方式，如下：

- 手工配置 : 显示地设置要使用的代理

- 预先配置浏览器 : 浏览器厂商或发行商会在将浏览器发送给其客户之前预先对浏览器（或所有其他的Web客户端）的代理设置进行手工配置
- 代理的自动配置（Proxy Auto-Configuration,PAC）：一个代理配置的js文件，客户端在请求之前会取回这个js文件，从而判断如何决定使用代理
- WPAD的代理发现 : Web代理自动发现协议(Web Proxy Autodiscovery Protocol, WPAD)，自动检测出浏览器可以从哪个"配置服务器"下载到一个自动配置文件
  - 动态主机配置协议(DHCP)
  - 服务定位协议(SLP)
  - DNS知名主机名
  - DNS SRV记录
  - TXT记录中的DNS服务URI

#### 追踪报文

##### Via首部

Via首部字段列出了与报文途径的每个中间节点（代理或网关）有关的信息。报文每经过一个节点，都必须将这个中间节点添加到Via列表的末尾。

```
Via: 1.1 proxy-62.irenes-isp.net, 1.0 cache.joes-hardware.com
```

Via首部字段用于记录报文的转发，诊断报文循环，标识请求/响应链上所有发送者的协议能力

代理应该在发送一条请求之前，在Via首部插入一个与其自身有关的独特字符串，并在输入的请求中查找这个字符串，以检测网络中是否存在路由循环

###### Via的语法

Via首部字段包含一个由逗号分隔的路标(waypoint)。每个路标都表示一个独立的代理服务器或网关，且包含与那个中间节点的协议和地址有关的信息。

##### TRACE方法

代理服务器可以在转发报文时对其进行修改。为了便于对代理网络进行诊断，需要有一种便捷的方式来观察在通过HTTP代理网络逐条转发报文的过程中，报文是怎样变化的。

当TRACE请求到达目的服务器时，整条请求报文都会被封装在一条HTTP响应的主体中回送给发送端。TRACE响应的Content-Type为message/http。

###### Max-Forwards

可以使用Max-Forwards首部来限制TRACE和OPTIONS请求所经过的代理跳数。Max-Forwards的值如果为零，那么即使接收者不是原始服务器，它也必须将TRACE报文回送给客户端，而不应该继续转发。如果收到的Max-Forwards值大于零，转发的报文中就必须包含一个更新了的Max-Forwards字段，其值会被减一。

### 缓存

#### 缓存的优点

- 缓存减少了冗余的数据传输，节省了网络费用

  每次都从原始服务器拿数据，那么带来的后果就是：多次发送重复的数据浪费流量、耗费昂贵的网络带宽从而降低传输速率、加大服务器的负载。而有了缓存之后这些问题都可以迎刃而解

- 缓存缓解了网络瓶颈的问题

  很多网络为本地客户端配置的带宽要比远程服务器配置的带宽要宽，如果在这种状况下客户端去请求远程服务器，那么客户端将会以一种的较低的速度去请求服务端，从而没有发挥出客户端带宽宽的长处！。如果在客户端方向配置一个高速缓存服务器，那么就可以很快的得到响应，由此也看出带宽对报文传输速率的影响

- 缓存降低了对原始服务器的要求

  一个爆炸性的新闻和热点事件，如果再没有配置缓存的情况下，那么在短时间之内，服务器将会收到突变的请求增长，负荷会爆炸性增长，肯定会吃不消的

- 缓存降低了距离时延

  距离时延说明的一个问题就是传输数据过程这个过程是需要时间的，而且路程越长，那么需要的时间也会越多，即时延越长。所以在距离客户端较近的地方部署缓存服务器，减小了传输路程，那么就减小了传输时延

#### 命中与未命中

可以用已有的副本为某些到达缓存的请求提供服务，被称为缓存命中。其他一些到达缓存的请求可能会由于没有副本可用，而被转发给原始服务器，被称为缓存未命中

缓存对缓存的副本进行再验证时，会向原始服务器发送一个小的再验证请求。如果内容没有变化，服务器会以一个小的304Not Modified进行相应。这被称为再验证命中或缓慢命中。最常用的是If-Modified-Since首部。

#### 缓存的拓扑结构

- 专用缓存被为私有缓存

  Web浏览器中有内建的私有缓存，大多数浏览器都会将常用文档缓存在个人电脑的磁盘和内存中，并且允许用户去配置缓存的大小和各种设置

- 共享缓存被称为公有缓存

代理缓存的层级结构：此种结构描述的以父、子层级出现的层次结构，同时离客户端越近的子缓存的命中率较低（较廉价），他们可以把请求上升到父缓存（较昂贵），从而在父缓存那里实现事务处理

*代理缓存的网状结构*描述的缓存结构并不是很明显呈现父子关系的结构，而是呈无规则的网状。这种结构的思想就是子缓存可以动态选择上一级缓存，从而实现更灵活的缓存控制

#### 缓存的处理步骤

- 接收 - 缓存从网络中读取抵达的请求报文
- 解析 - 缓存对报文进行解析，提取出URL和各种首部
- 查询 - 缓存查看是否有本地副本可用，如果没有，就获取一份副本(并将其保存在本地)
- 新鲜度检测 - 缓存查看已缓存副本是否足够新鲜，如果不是，就询问服务器是否有任何更新
- 创建响应 - 缓存会用新的首部和已缓存的主题来构建一条响应报文
- 发送 - 缓存通过网络将响应发回给客户端
- 日志 - 缓存可选地创建一个日志文件条目来描述这个事务

#### 保持副本的新鲜

HTTP将这些简单的机制称为**文档过期(document expiration)**和**服务器再验证(server revalidation)**

##### 文档过期

通过特殊的HTTP **Cache-Control: max-age**首部(HTTP1.1)和**Expires**首部(HTTP1.0+)，HTTP让原始服务器向每个文档附加一个"过期日期"。二者的区别在于，Cache-Control首部使用的是相对时间而不是绝对日期。

##### 服务器再验证

服务器再验证，说明缓存需要询问原始服务器文档是否发生了变化。最好用的两个首部是**If-Modified-Since**和**If-None-Match**。

- If-Modified-Since，可以与Last-Modified服务器响应首部配合使用
- If-None-Match，服务器可以为文档提供特殊的标签(ETag)

#### 控制缓存的能力

缓存控制能力描述的是服务器可以通过设置相关首部来控制文档的缓存过期时间的能力

- ```
  Cache-Control: no-store //不能缓存
  	
  Cache-Control: no-cache //实际可以存储在本地缓存区中，只是在于原始服务器进行新鲜度再验证之前，缓存不能将其提供给客户端使用
  	
  Cache-Control: must-revalidate //严格遵守新鲜验证规则
  	
  Cache-Control: max-age //设置多长时间的过期时间（相对时间）
  	
  Expires: <date> //设置多长的过期时间（绝对时间）
  ```

### 集成点：网关、隧道及中继

网关可以作为某种翻译器使用，抽象出了一种能够到达资源的方法。网关是资源和应用程序之间的粘合剂。应用程序可以(通过HTTP或其他已定义的接口)请求网关来处理某条请求，网关可以提供一条响应。

有些网关会自动加你HTTP流量转换为其他协议，这样HTTP客户端无需了解其他协议，就可以与其他应用程序进行交互。

网关类型：

- 服务器协议转换器

- 服务器安全网关

- 客户端安全网关

- 应用程序服务器

  最常见的是应用程序服务器，会将目标服务器与网关结合在一个服务器中实现。应用程序服务器是服务器端网关，与客户端通过HTTP进行通信，并与服务器端的应用程序相连

  应用程序服务器并没有回送文件，而是将请求通过一个网关应用编程接口(Application Programming Interface, API)发送给运行在服务器上的应用程序。

#### 隧道

Web隧道(Web tunnel)，可以通过HTTP应用程序访问使用非HTTP协议的应用程序

Web隧道允许通过HTTP连接非HTTP流量，这样就可以在HTTP上捎带其他协议数据。使用Web隧道最常见的原因就是要在 HTTP连接中嵌入非HTTP流量，这类流量就可以穿过只允许Web流量通过的防火墙

Web隧道是用HTTP的CONNECT方法建立起来的。

客户端发送了一条CONNECT请求给隧道网关。客户端的CONNECT方法请求隧道网关打开一条TCP连接。创建TCP连接后，网关就会发送一条HTTP 200响应来通知客户端。此时，隧道建立起来了。客户端通过HTTP隧道发送的所有数据都会被直接转发给输出TCP连接，服务器发送的所有数据都会通过HTTP隧道转发给客户端。

##### CONNECT请求

除了起始行之外，和其他HTTP方法类似。只是后面跟着冒号和端口号的主机名取代了请求URI

```
CONNECT home.netscape.com:443 HTTP/1.0
User-agent: Mozilla/4.0
```

##### CONNECT响应

与普通HTTP响应不同，这个响应并不需要包含Content-Type首部

#### SSL隧道

隧道会通过一条HTTP连接来传输SSL流量，以穿过端口80的HTTP防火墙。

##### SSL隧道与HTTP/HTTPS网关的对比

- 对HTTPS协议进行网关操作：由网关初始化与远端HTTPS服务器的SSL会话，然后代表客户端执行HTTPS事务。响应会由代理接收并解密，然后通过HTTP传送给客户端。很明显，这里存在的问题是客户端到网关之间的链接是普通的非安全HTTP；远端客户端无法对远端服务器执行SSL客户端认证；网关要支持完整的SSL实现
- SSL隧道机制无需在代理中实现。中间的代理服务器只是将加密数据经过隧道传输，并不会在安全事务中扮演其他的角色

#### 中继

中继负责处理HTTP中建立连接的部分，然后对字节进行盲转发。

HTTP很复杂，实现基本的代理功能并对流量进行盲转发，不执行任何首部和方法逻辑，有时是很有用的。但是必须要小心的是，对Connection等首部的处理。会带来潜在的挂起keep-alive连接问题。

### Web机器人

Web机器人是能够在无需人类干预的情况下自动进行一系列Web事务处理的软件程序。很多机器人会从一个Web站点逛到另一个Web站点，获取内容，跟踪超链，并对它们找到的数据进行处理。因此也形象的给他们取了名字，比如"爬虫"、"蜘蛛"、"蠕虫"以及"机器人"。

#### 爬虫及爬行方式

Web爬虫是一种机器人，它们会递归地对各种信息性Web站点进行遍历，获取第一个Web页面，然后获取那个页面指向的所有Web页面，然后是那些页面指向的所有Web页面，以此类推。

爬虫会从根集开始爬行；爬虫会解析页面所有的url，并把他们转换绝对形式；爬行要避免环路的出现，这些环路会带来有害的影响：

- 会使爬虫陷入可能会将其困住的循环之中。会一直兜圈子，把所有时间都好在了不停地获取相同的页面上。会消耗掉很多网络带宽，可能完全无法获取任何其他页面。
- 爬虫不断地获取相同的页面时，另一端的Web服务器也在遭受攻击。会阻止所有真实用户访问这个站点。
- 即使循环自身不是问题，但是爬虫也会获取大量重复的页面。爬虫应用程序最终会被重复的内容所充斥。

网络中两个url表面上看起来不一样，但是指向的是同一资源，那么这两个url就互相称为“别名”，由于别名问题的存在，所以爬虫会爬行重复的数据，所以爬虫有必要把url的进行规范化。如为没有指定端口的主机名添加":80"；将所有转义符%xx都转换成等价字符；删除#标签。但这些操作也只能解决简单的别名问题。因为有些问题在不知道特定Web服务器的相关信息时是没有好办法避免的。

##### 避免循环和重复

- 规范化URL - 将URL转换为标准形式以避免语法上的别名
- 广度优先的爬行 - 以广度优先的方式来调度URL去访问Web站点，就可以将环路的影响最小化。如果采用深度优先方式，一头扎到单个站点中去，就可能会跳入环路，永远无法访问其他站点
- 节流 - 限制一段时间内机器人可以从一个Web站点获取的页面数量
- 限制URL的大小 - 机器人可能会拒绝爬行超出特定长度(通常是1KB)的URL。这种技术肯定会错过一些内容，因为现在很多站点都会用URL来管理用户的状态，使URL的长度变得足够长
- URL/站点黑名单 - 维护一个与机器人环路和陷阱相对应的已知站点及URL列表。发现新问题时，就将其加入黑名单
- 模式检测 - 文件系统的符号连接和类似的错误配置所造成的环路会遵循某种模式，如URL会随着组件的复制逐渐增加
- 内容指纹 - 使用内容指纹的机器人会获取页面内容中的字节，并计算出一个校验和(checksum)。这个校验和是页面内容的压缩表示形式。MD5是常用的指纹计算函数
- 人工监视

#### 机器人的HTTP

在追踪错误爬虫的所有者，以及想服务器提供机器人所能处理的内容类型时，以下信息是很有用的：

- User-agent - 将发起请求的机器人名字告知服务器
- From - 提供机器人的用户/管理者的E-mail地址
- Accept - 告知服务器可以发送哪些媒体类型
- Referer - 提供包含了当前请求URL的文档的URL

虚拟主机需要爬虫带HOST首部，不然会返回错误主机的数据

##### 条件请求

有些机器人实现条件HTTP请求，他们会对时间戳或实体标签进行比较，看看它们最近获取的版本是否已经升级了。这与HTTP缓存查看已获取资源的本地副本是否有效的方法非常相似。

##### 对响应的处理

一般，机器人主要在于用简单的GET方法来获取所请求的内容，所以，一般不会再处理响应的方式上花费太多时间。但是，如果想要更好地探索服务器，机器人应该能对各种不同类型的HTTP响应进行处理

- 状态码 - 机器人至少应该能够处理一些常见的，以及预期的状态码。如200和404
- 实体 - 除了HTTP首部所嵌的信息之外，机器人也会在实体中查找信息。HTML元标签，如http-equiv，就是内容编写者用于嵌入资源附件信息的一种方式

#### 行为不当的机器人

- 失控的机器人，比正常用户的请求速度快很多，当这类爬虫设计出现错误的时候，很容易短时间之内增加服务器的负载，阻止真正用户的访问，原因诸如：编程逻辑错误、陷入环路之中
- 失效的url，url可能已经失效了，但是爬虫依然取请求它 ，这样会让服务器的日志文档里面增加了很多请求出错的记录。
- 很长的错误url,同样请求这样一个url，会让服务器日志文档增加一个很杂论的出错记录
- 爱打听的机器人，访问了一些管理者不允许访问的内容，涉及侵犯隐私
- 动态网关访问

#### 拒绝机器人访问

"拒绝机器人访问标准"，通常只是根据存储访问控制信息的文件而将其称为robots.txt

所有Web服务器都可以在服务器的文档根目录中提供一个可选的、名为robots.txt的文件。这个文件包含的信息说明了机器人可以访问服务器的哪些部分。

如果一个Web站点有robots.txt文件，那么在访问这个Web站点上的任意URL之前，机器人都必须获取它并对其进行处理。由主机名和端口号定义的整个Web站点上仅有一个robots.txt资源。如果是虚拟主机，每个虚拟的docroot都可以有一个不同的robots.txt文件。

如果服务器以404Not Found HTTP状态码进行响应，机器人就可以认为这个服务器上没有机器人访问限制，它可以请求任意的文件。

机器人应在From首部和User-Agent首部中传输标识信息，以帮助站点管理者对机器人的访问进行跟踪。

请求robots.txt是针对服务器返回的状态码，爬虫所作的动作：

- 如果返回2xx代码，机器人就必须对内容进行解析，并使用排斥规则从那个站点上获取内容
- 如果返回404，机器人认为服务器没有激活排斥规则，所以它不受限制
- 如果返回401或403(访问限制)，表示机器人是完全受限的
- 如果返回503（服务器临时故障），那么机器人暂时停止访问，知道正常之后继续请求robots.txt
- 如果返回重定向代码，那么机器人也应该重定向到相关页面

robots.txt文件中有三种类型行：空行、注释行和规则行。

```
User-Agent: slurp
User-Agent: websrawler
Disallow: /private

User-Agent: *
Disallow: 
```

##### HTML的robot-control元标签

可以直接在HTML文档中添加robot-control标签。遵循robot-controlHTML标签规则的机器人仍然可以获取文档，但如果其中有机器人排斥标签，它们都会忽略这些文档。

```
<meta name="robots" content: directie-list>
```

最常用的两个机器人META指令是：

- NOINDEX - 告诉机器人不要对页面的内容进行处理，忽略文档(也就是，不要在任何索引或数据库中包含此内容)
- NOFOLLOW - 告诉机器人不要爬行这个页面的任何外链连接

### HTTP-NG

HTTP发展中至少存在4个方面的问题

- 复杂性 - http相当复杂，而且特性之间是相互依存的
- 可扩展性 - 很难实现递增式扩展
- 性能 - 不好，有些造成时延较大
- 传输依赖性

#### 模块化及功能增强

HTTP-NG工作组建议将协议模块化为三层

- 报文传输层(message transport layer)，不考虑报文的功能，致力于端点间的报文的不透明传输

  报文传输层关心的是报文的有效传输，不考虑报文的含义和目的。报文传输层为报文传输提供了一个API，无论底层实际采用的是什么网络协议栈都可以使用，本层关注的是提高报文传输的功能，包括：

  - 对报文进行管道化和批量化传输，以降低往返时延
  - 重用连接，以降低时延，提高传输带宽
  - 在同一条连接上并行地复用多个报文流，在防止报文流饿死的同时优化共享连接
  - 对报文进行有效的分段，使报文边界的确定更加容易

  WebMUX：是一个复杂的高性能报文系统，可以在一个复用的TCP连接上并行地传输报文。可以对以不同速度产生和消耗的独立报文流进行高效的分组，并将复用到一条或少数几条TCP连接上去

- 远程调用层(remote invocation layer)，定义了请求/响应的功能，客户端可以通过这些功能调用对服务器资源的操作

  本层不关心特定操作的实现及语义(缓存、安全性以及方法逻辑等)；它只关心允许客户端远程调用服务器操作的接口

- Web应用层(Web application layer)，提供了大部分的内容管理逻辑。所有HTTP1.1方法(GET、POST、PUT等)，以及HTTP/1.1首部参数都是在这里定义



## SPDY/HTTP2.0

HTTP2.0的目的是通过`支持请求与响应的多路复用`来减少延迟，通过`压缩HTTP首部字段`将协议开销降低至最低，同时增加对`请求优先级`和`服务端推送`的支持，修改了`流量控制`、`错误处理`和`更新机制`。

HTTP2.0增加了`二进制分帧层`，定义了如何封装HTTP消息并在客户端与服务器之间传输。HTTP1.x以换行符作为纯文本的分隔符，HTTP2.0将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。

### 流、消息、帧

- 流 - 已建立的连接上的双向字节流
- 消息 - 与逻辑消息对应的完整的一系列数据帧
- 帧 - HTTP2.0的最小单位，每个帧包含`帧首部`，至少也会标识出当前帧所属的流

所有HTTP2.0通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。每个数据流以消息的形式发送，而消息由一到多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装

### 二进制分帧层

HTTP2.0性能增强的核心，全在于新增的二进制分帧层。定义了如何封装HTTP消息并在客户端与服务器之间传输

![binary-frames](http://www.reyshieh.com/assets/binary-frames.png)

"层"指的是位于套接字接口与应用可见的高层HTTP API之间的一个新机制，HTTP的语义不受影响，不同的是传输期间的编码发生了变化

### 二进制分帧

HTTP2.0建立连接后，客户端与服务端会通过交换帧来通信，帧是基于这个新协议通信的最小单位。所有帧都共享一个8字节的首部，其中包含帧的长度、类型、标志，还有一个保留位和一个31位的流标识符

![http2-binary-summary](http://www.reyshieh.com/assets/http2-binary-summary.png)

- 16位的长度前缀意味着一帧大约可以携带64KB数据，不包括8字节首部
- 8位的类型字段决定如何解释帧其余部分的内容
- 8位的标志字段允许不同的帧类型定义特定于帧的消息标志
- 1位保留字段始终为0
- 31位的流标识符唯一标识HTTP2.0的流

帧类型包括：

- DATA：用于传输HTTP消息体
- HEADERS：用于传输关于流的额外的首部字段
- PRIORITY：用于指定或重新指定引用资源的优先级
- RST_STREAM：用于通知流的非正常终止
- SETTINGS：用于通知两端通信方式的配置数据
- PUSH_PROMISE：用于发出创建流和服务器引用资源的要约
- PING：用于计算往返时间，执行“活性”检查
- GOAWAY：用于通知对端停止在当前连接中创建流
- WINDOW_UPDATE：用于针对个别流或个别连接实现流量控制
- CONTINUATION：用于继续一系列首部块片段

利用GOAWAY类型的帧，告诉客户端要处理的最后一个流ID，从而消除一些请求竞争，而且浏览器也可以据此智能地重试或取消"悬着的"请求，这是保证复用连接的一个重要功能

在发送应用数据之前，必须创建一个**新流**并随之发送相应的元数据，比如流优先级、HTTP首部等。HTTP2.0规定客户端和服务器都可以发起新流，存在两种可能：

- 客户端通过发送HEADERS帧来发起新流，帧包含带有新流ID的公用首部、可选的31位优先值，以及一组HTTP键-值对首部

  ![http2-headers-priority](http://www.reyshieh.com/assets/http2-headers-priority.png)

- 服务器通过发送PUSH_PROMISE帧来发起推送流，和HEADERS帧等效，但包含"要约流ID"，没有优先值

- HEADERS帧和PUSH_PROMISE帧都只用于沟通新流的元数据，净荷会在DATA帧中单独发送。规定，客户端发送的流具有奇数ID，服务器发起的流具有偶数ID。两端的流ID不会冲突，各自持有一个简单的计数器

### 多向请求与响应

二进制分帧层的加入，实现了多向请求和响应，客户端和服务器可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来

![http2-request-mor](http://www.reyshieh.com/assets/http2-request-more.png)

>注意，HTTP2.0加入了多向请求与响应，为了优化HTTP1.x的方案，如拼接文件、图片精灵、域名分区都变得没有必要。而且这些优化有可能反而带来更大的消耗。同时这个方式减少TCP连接的数量，也会减少客户端和服务器CPU及内存占用

### 请求优先级

每个流都可以带有一个31比特的优先值：

- 0表示最高优先级
- 2^31 - 1表示最低优先级

客户端和服务器可以在处理不同的流时采用不同的策略，以最优的方式发送流、消息和帧。

HTTP2.0并没有规定处理优先级的具体算法，只是提供了一种赋予数据优先级的机制。因此，对应的次序排定策略可能因客户端或服务器的实现而不同：客户端应该明确指定优先值，服务器应该根据该值处理和交付数据

但是，同样还是要考虑些问题。如果服务器不去理会所有优先值，那么可能会导致应用响应变慢，浏览器在需要等关键CSS和JS时，服务器却发送了图片，造成渲染阻塞。但是严格的优先级次序也可能带来次优的效果，因为可能又会引入队首阻塞问题，即某个高优先级的慢请求会不必要地阻塞其他资源的交付

因此，服务器可以交错发送不同优先级的帧。只要可能，高优先级流都应该优先，包括分配处理资源和客户端与服务器间的带宽

### 流量控制

HTTP2.0为数据流和连接的流量控制提供了一个简单的机制：

- 流量控制基于每一跳进行，并不是端到端的控制
- 流量控制基于窗口更新帧进行，即接收方广播自己准备接收某个数据流的多少字节，以及对整个连接要接收多少字节
- 流量控制窗口大小通过WINDOW_UPDATE帧更新，字段指定了流ID和窗口大小递增值
- 流量控制有方向性，即接收方可能根据自己的情况为每个流乃至整个连接设置任意窗口大小
- 流量控制可以由接收方禁用，包括针对个别的流和针对整个连接

### 服务端推送

HTTP2.0允许服务器对客户端请求发送多个响应。除了最初请求的响应外，服务器还可以额外向客户端推送资源，无需客户端明确地请求

服务器将资源直接推送给客户端，带来了好处：

- 客户端可以缓存推送过来的资源
- 客户端可以拒绝推送过来的资源
- 推送资源可以由不同的页面共享
- 服务器可以按照优先级推送资源

推送的资源必须遵循同源策略。服务器不能随便讲第三方资源推送给客户端，必须是经过双方确认的才行

推送的资源将直接进入客户端缓存

### 首部压缩

HTTP2.0在客户端和服务器端使用"首部表"来跟踪和存储之前发送的键-值对，相同的数据不再通过每次请求和响应发送

首部表在HTTP2.0的链接存续期内始终存在，由客户端和服务器共同渐进地更新

每个新的首部键-值对要么被追加到当前表的末尾，要么替换表中的值

![http2-header-diff](http://www.reyshieh.com/assets/http2-header-diff.png)

### HTTP2.0升级与发现

因为HTTP1.x在短时间内是不会去除的，存在很长一段时间内HTTP1.x和HTTP2.0并存。于是，支持HTTP2.0的客户端在发起请求之前，必须能发现服务器及所有中间设备是否支持HTTP2.0协议。存在三种情况：

- 通过TLS和ALPN(应用层协议协商，Application Layer Protocol Negotiation)发起新的HTTPS连接
- 根据之前的信息发送新的HTTP连接
- 没有之前的信息而发起新的HTTP连接

减少网络延迟是HTTP2.0的关键条件，因此在建立HTTPS连接时一定会用到ALPN协商

HTTP1.0和HTTP2.0都使用同一个端口(80)，且没有服务器是否支持HTTP2.0的其他任何信息，此时客户端只能使用HTTP upgrade机制通过协调确定适当的协议

```
GET /page HTTP/1.1
Host server.example.com
Connection: Upgrade, HTTP2-Settings
Upgrade: HTTP/2.0
HTTP2-Settings: (SETTINGS payload)

// 响应 http1.1方式
HTTP/1.1 200 OK
Content-length: 243
Content-type: text/html
// 响应 http2.0方式
HTTP/1.1 101 Switching Protocols
Connection: Upgrade
Upgrade: HTTP/2.0
```

如果客户端因为自己保存有或通过其他手段（如DNS记录、手工配置等）获得了关于HTTP2.0的支持信息，也可以直接发送HTTP2.0分帧，而不必依赖Upgrade机制

最坏的情况就是无法建立连接，客户端再回退一步。重新使用Upgrade首部，或者切换到带ALPN协商的TLS信道

### HTTP1.x和2.0相互转换

如果客户端与服务器端不能保证两端同事支持HTTP2.0，那么可以新增一个转换层，使1.x服务器利用HTTP2.0

一台服务器可以接受HTTP2.0会话，处理之后再向既有基础设施分派1.x格式的请求。接到响应后，再将其转换成HTTP2.0的流返回给客户端