# http/http2/https

## HTTP

### headers

#### 请求头

1. <u>Accept</u>：用来告知客户端可以处理的内容类型，这种内容类型用MIME类型来表示。借助内容协商机制，服务器可以从诸多备选项中选择一项进行应用，并使用**Content-Type**应答头通知客户端它的选择。

< MIME_type >/< MIME_subtype >

< MIME_type >/*

*/ * 任意类型的MIME类型

;q=(q因子权重)

如： text/html,application/xhtml+xml,application/xml;q=0.9, * /*;q=0.8

2. <u>Accept-Charset</u>：请求头用来告知（服务器）客户端可以处理的字符集类型。借助内容协商机制，服务器可以从诸多备选项中选择一项进行应用，并使用**Content-Type**应答头通知客户端它的选择。通常不会设置此项。

<**charset**> utf-8或iso-8895-1字符集

*** 通配符**

;q=

3. <u>Accept-Encoding</u>：将客户端能够理解的内容编码方式进行通知。使用并在相应报文首部**Content-Encoding**中通知客户端选择

压缩方式包括gzip（Lempel-Ziv coding压缩算法（LZ77）+32位CRC校验的编码方式）、compress（Lempel-Ziv-Welch（LZW））、deflate（zlib结构+deflate压缩算法）、br（Brotli算法）、identity（保持自身）、*（匹配其他任意未在首部字段中列出的编码方式）

identity不压缩存在两种情形：a.要发送的数据已经经过压缩，再次进行压缩不会导致被传输的数据量更小，如图像格式 b.服务器超载，无法承受压缩需求导致的计算开销，通常，如果服务器使用超过80%的计算能力，不建议压缩

4. Accept-Language：允许客户端声明它可以理解的自然语言，以及优先选择的区域方言，并使用**Content-Language**应答头通知客户端它的选择。

5. Accept-Ranges：标识自身支持范围请求（partial requests）。当浏览器发现Accept-Range头时，可以尝试继续中断了的下载，而不是重新开始

none：在一些浏览器，如IE9，会依据该头部去禁用或者移除下载管理器的暂停按钮

bytes

6. Access-Control-Allow-Credentials：表示是否可以将对请求的响应暴露给页面。Credentials可以是<u>cookies，authorization headers 或TLS client certificates</u>

当作为对预检请求的响应的一部分时，这能表示是否真正的请求可以使用credentials。注意GET请求**没有预检**，所以若对资源的请求带有了credentials，响应会被浏览器忽视

Access-Control-Allow-Credentials头需与XMLHttpRequest.withCredentials或Fetch api中的Request()构造器中的credentials选项结合使用

Access-Control-Allow-Credentials: true

使用带credentials的XHR：

```
var xhr = new XMLHttpRequest();
xhr.open('GET', 'http://example.com/', true);
xhr.withCredentials = true;
xhr.send(null);
```

使用带credentials的Fetch：

```
fetch(url, {
    credentials: 'include'
})
```

7. Access-Control-Allow-Headers：用于**预检请求**中，列出将会在正式请求的**Access-Control-Expose-Headers**字段中出现的首部信息

简单首部，如 [simple headers](https://developer.mozilla.org/en-US/docs/Glossary/simple_header)、[`Accept`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept)、[`Accept-Language`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept-Language)、[`Content-Language`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Language)、[`Content-Type`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type) （只限于解析后的值为 `application/x-www-form-urlencoded、``multipart/form-data `或 `text/plain 三种MIME类型（不包括参数）），它们始终是被支持的，不需要在这个首部特意列出。`

如果请求中含有 [`Access-Control-Request-Headers`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Access-Control-Request-Headers) 字段，那么这个首部是必要的。

8. Access-Control-Allow-Methods：对**预检请求**的应答明确了客户端所要访问的资源允许使用的方法或方法列表

Access-Control-Allow-Methods: POST,GET,OPTIONS

9. Access-Control-Allow-Origin：指定了该响应的资源是否允许与给定的origin共享

***** 允许所有域都具有访问资源的权限

<**origin**> 指定一个可以访问资源的URI

10. Access-Control-Expose-Headers：列出哪些首部可以作为响应的一部分暴露给外部

默认情况下，Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma简单响应首部是可以暴露给外部的，其他的首部需要在里面列出来

11. Access-Control-Max-Age：表示**预检请求**的返回结果（即Access-Control-Allow-Methods和Access-Control-Allow-Headers提供的信息）可以被缓存多久

在Firefox中，上限是24小时（即87400秒），在Chromium中则是10分钟（即600秒）还规定了默认值是5秒

若值为-1，表示禁用缓存。每一次请求都需要提供预检请求，即用OPTIONS请求进行预检

12. Access-Control-Request-Headers：出现在**预检请求**中，用于通知服务器在真正的请求中会采用哪些请求首部

13. Access-Control-Request-Method：出现在**预检请求**中，用于通知服务器在真正的请求中会采用哪种HTTP方法。因为预检请求所使用的方法总是OPTIONS，与实际请求所使用的方法不一样，**所以这个首部是必要的**

14. Age：消息头里包含消息对象在缓存代理中存储的时长，以秒为单位

Age消息头的值通常接近于0.表示此消息对象刚刚从原始服务器获取不久；其他的值表示代理服务器当前的系统时间与此应答消息中的通用**消息头Date**的值之差

15. Allow：用于枚举资源所支持的HTTP方法的集合

若服务器返回状态码 [`405`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/405) `Method Not Allowed，则该首部字段亦需要同时返回给客户端。如果` `Allow`  首部字段的值为空，说明资源不接受使用任何 HTTP 方法的请求。这是可能的，比如服务器需要临时禁止对资源的任何访问。

16. Authorization：请求消息头含有服务器用于验证用户代理身份的凭证，通常会在服务器返回[`401`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/401) `Unauthorized` 状态码以及[`WWW-Authenticate`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/WWW-Authenticate) 消息头之后在后续请求中发送此消息头。

17. Cache-Control：用于http请求和响应中通过指定指令来实现缓存机制。缓存指令是单向的，意味着在请求设置的指令，在响应中不一定包含相同的指令。

- 缓存请求指令

  ```
  Cache-Control: max-age=<seconds>(最大存储周期，相对于请求的时间)
  Cache-Control: max-stale[=<seconds>](表明客户端愿意接收一个已经过期的资源。 可选的设置一个时间(单位秒)，表示响应不能超过的过时时间)
  Cache-Control: min-fresh=<seconds>(表示客户端希望在指定的时间内获取最新的响应)
  Cache-control: no-cache 
  Cache-control: no-store
  Cache-control: no-transform
  Cache-control: only-if-cached(表明客户端只接受已缓存的响应，并且不要向原始服务器检查是否有更新的拷贝)
  ```

- 缓存响应指令

  ```
  Cache-control: must-revalidate(缓存必须在使用之前验证旧资源的状态，并且不可使用过期资源)
  Cache-control: no-cache(在释放缓存副本之前，强制告诉缓存将请求提交给原始服务器进行验证)
  Cache-control: no-store(缓存不应存储有关客户端请求或服务器响应的任何内容)
  Cache-control: no-transform(不得对资源进行转换或转变)
  Cache-control: public(可缓存，表明响应可以被任何对象缓存)
  Cache-control: private(可缓存，表明响应只能被单个用户缓存，不能作为共享缓存，即代理服务器不能缓存)
  Cache-control: proxy-revalidate(与must-revalidate作用相同，但它仅适用于共享缓存（例如代理），并被私有缓存忽略)
  Cache-Control: max-age=<seconds>
  Cache-control: s-maxage=<seconds>(覆盖max-age 或者 Expires 头，但是仅适用于共享缓存(比如各个代理)，并且私有缓存中它被忽略。)
  ```

- 拓展Cache-Control指令

  ```
  Cache-control: immutable (表示响应正文不会随时间而改变)
  Cache-control: stale-while-revalidate=<seconds>(表明客户端愿意接受陈旧的响应，同时在后台异步检查新的响应。秒值指示客户愿意接受陈旧响应的时间长度)
  Cache-control: stale-if-error=<seconds>(表示如果新的检查失败，则客户愿意接受陈旧的响应。秒数值表示客户在初始到期后愿意接受陈旧响应的时间)
  ```

禁止缓存

```
Cache-Control: no-cache, no-store, must-revalidate
```

缓存静态资源

```
Cache-Control: public, max-age=31536000
```

18. Clear-Site-Data：表示清除当前请求网站有关的浏览器数据（cookie，存储，缓存）。若想清楚所有类型的数据，可以使用通配符（*）

```
// 单个参数
Clear-Site-Data: "cache"
// 多个参数(用逗号分隔)
Clear-Site-Data: "cache", "cookies"
```

参数：

- "cache" 服务端希望删除本URL原始响应的本地缓存数据。根据浏览器不同，可能还会清除预渲染页面，脚本缓存，WebGL着色器缓存或者地址栏建议等内容
- "cookies"服务端希望删除URL响应的所有cookie。HTTP身份验证凭据也会被清除
- "storage"服务端希望删除URL原响应的所有DOM存储，包括存储机制，如localStorage、sessionStorage、IndexedDB、服务注册线程、AppCache、WebSQL数据库、FileSystem API data、Plugin data
- "executionContexts" 服务端希望浏览器重新加载本请求（location.reload）
- "*" 服务端希望清除原请求响应的所有类型的数据

**登出**，如果用户退出网站或服务，希望删除本地存储的数据。可以在https://example.com/logout的**响应头**增加Clear-Site-Data

```
Clear-Site-Data: "cache", "cookies", "storage", "executionContexts"
```

清除cookies，如果在https://example.com/clear-cookies的响应头中出现，则同一域和所有子域（如https://stage.example.com等）的所有Cookie，都会被清除

```
Clear-Site-Data: "cookies"
```

19. Connection：决定当前的事务完成后，是否会关闭网络连接。如果该值是“keep-alive”，网络连接就是持久不会关闭的。keep-alive不是必须填的

20. Content-Disposition：指示回复的内容该以何种形式展示，以内联（**inline**）即网页或者页面的一部分，还是附件（attachment）的形式下载并保存到本地，大多数浏览器会呈现一个“保存为”的对话框，将filename的值预填为下载后的文件名

Content-Disposition: inline

Content-Disposition: attachment

Content-Disposition: attachment; filename="filename.jpg"

21. Content-Encoding：实体消息首部，用于对特定媒体类型的数据进行压缩。对于特定类型的文件，比如jpeg图片文件，已经进行压缩过的，就不需要继续压缩

22. Content-Language：用来说明访问者希望采用的语言或语言组合，这样的话用户就可以根据自己偏好的语言来定制不同的内容

23. Content-Length：用来指名发送给接收方的消息主体的大小，用十进制数字表示

24. Content-Location：首部指定的是要返回的数据的地址选项。最主要的用途是用来指定要访问的资源经过内容协商后的结果的URL

**Location**-指定的是一个重定向请求的目的地址（或者新创建的文件的URL）-对应的是响应

Content-Location-指向的是可供访问的资源的直接地址，不需要进行进一步的内容协商-对应的是要返回的实体

25. Content-Range：显示的是一个数据片段在整个文件中的位置

Content-Range: <**unit**>  <**range-start**>-<**range-end**>/<**size**>

Content-Range: <**unit**>  <**range-start**>-<**range-end**>/*

Content-Range: <**unit**>  */<**size**>

unit-数据区间所采用的单位。通常是字节（byte）

range-start-区间起始值

range-end-区间的结束值

size-整个文件的大小

26. Content-Security-Policy：允许站点管理者在指定的页面控制用户代理的资源。主要以白名单的形式配置可信任的内容来源，在网页中，能够使用白名单中的内容正常执行（包含JS、CSS、Image等），而非白名单的内容无法正常执行，这条策略将极大的指定服务源以及脚本端点。减少**跨站点脚本攻击（XSS）**，也能减少**运营商劫持的内容注入攻击**

Head中添加Meta标签示例

```
<meta http-equiv="Content-Security-Policy" content="script-src 'self'">
```

不支持CSP的浏览器将会自动忽略CSP的信息，不会有什么影响

当定义多个策略的时候，浏览器会优先采用最先定义的。

| 指令            | 取值示例                  | 说明                                                         |
| --------------- | ------------------------- | ------------------------------------------------------------ |
| default-src     | 'self' cdn.example.com    | 定义针对所有类型（js/image/css/web font/ajax/iframe/多媒体等）资源的默认加载策略，某类型资源如果没有单独定义策略，就使用默认。 |
| script-src      | 'self' js.example.com     | 定义针对JavaScript的加载策略                                 |
| object-src      | 'self'                    | 针对,, 等标签的加载策略                                      |
| style-src       | 'self' css.example.com    | 定义针对样式的加载策略                                       |
| img-src         | 'self' image.example.com  | 定义针对图片的加载策略                                       |
| media-src       | 'media.example.com'       | 针对或者引入的html多媒体等标签的加载策略                     |
| frame-src       | 'self'                    | 针对iframe的加载策略                                         |
| connect-src     | 'self'                    | 针对Ajax、WebSocket等请求的加载策略。不允许的情况下，浏览器会模拟一个状态为400的响应 |
| font-src        | font.qq.com               | 针对Web Font的加载策略                                       |
| sandbox         | allow-forms allow-scripts | 对请求的资源启用sandbox                                      |
| report-uri      | /some-report-uri          | 告诉浏览器如果请求的资源不被策略允许时，往哪个地址提交日志信息。不阻止任何内容，可以改用Content-Security-Policy-Report-Only头 |
| base-uri        | 'self'                    | 限制当前页面的url（CSP2）                                    |
| child-src       | 'self'                    | 限制子窗口的源(iframe、弹窗等),取代frame-src（CSP2）         |
| form-action     | 'self'                    | 限制表单能够提交到的源（CSP2）                               |
| frame-ancestors | 'none'                    | 限制了当前页面可以被哪些页面以iframe,frame,object等方式加载（CSP2） |
| plugin-types    | application/pdf           | 限制插件的类型（CSP2）                                       |
| manitest-src    |                           | 限制application manifest文件源                               |
| worker-src      |                           | 限制Worker，SharedWorker或者ServiceWorker脚本源              |
| disown-opener   |                           | 确保资源在操作的时候能够脱离父页面                           |
| navigation-to   |                           | 限制文档可以通过以下任何方式访问URL（a，form，window.location，window.open，etc） |
| report-to       |                           | Fires a `SecurityPolicyViolationEvent`                       |

指令值示例及说明

| 指令值                              | 示例                                        | 说明                                                         |
| ----------------------------------- | ------------------------------------------- | ------------------------------------------------------------ |
| *                                   | img-src *                                   | 允许任何内容                                                 |
| none'                               | img-src 'none'                              | 不允许任何内容                                               |
| 'self'                              | img-src 'self'                              | 允许同源内容                                                 |
| data:                               | img-src data:                               | 允许data:协议（如base64编码的图片）                          |
| [www.a.com](http://www.a.com/)      | img-src [www.a.com](http://www.a.com/)      | 允许加载指定域名的资源                                       |
| *.a.com                             | img-src *.a.com                             | 允许加载a.com任何子域的资源                                  |
| [https://img.com](https://img.com/) | img-src [https://img.com](https://img.com/) | 允许加载img.com的https资源                                   |
| https:                              | img-src https:                              | 允许加载https资源                                            |
| 'unsafe-inline'                     | script-src 'unsafe-inline'                  | 允许加载inline资源（style属性，onclick，inline js和inline css等等） |
| 'unsafe-eval'                       | script-src 'unsafe-eval'                    | 允许加载动态js代码，例如eval()                               |

CSP使用方式

HTML Meta标签

Meta标签主要含有两部分的key-value：

- http-equiv
- content

```
<meta http-equiv="Content-Security-Policy" content="script-src 'self'">
```

HTTP Header

通过HTTP header带上CSP的指令，可以支持所有请求

```
Content-Security-Policy: script-src 'self' *.qq.com *.url.cn
```

27. Content-Security-Policy-Report-Only：响应头允许通过监测策略，生成JSON文档，通过POST请求发送到指定的URI，该策略只会返回报告，不会阻止运行，这是和Content-Security-Policy的却别

28. Content-Type：用于指示资源的MIME类型media type。在响应中，Content-Type标头告诉客户端实际返回的内容的内容类型。浏览器会在某些情况下进行MIME查找，并不一定遵循此标题的值；为了防止这种行为，可以将标题**X-Content-Type-Options**设置为**nosniff**

29. Cookie：存放由服务端通过Set-Cookie设置的HTTP cookies

30. DNT（Do Not Track）：表明用户对于网站追踪的偏好。DNT: 0/1

0-表示用户愿意目标站点追踪用户个人信息

1-表示用户不愿意目标站点追踪用户个人信息

31. Date：包含了消息生成的日期和时间

32. Etag：资源的特定版本的标识符。让缓存更高效，并节省带宽，如果内容没有改变，Web服务器不需要发送完整的响应。Etag可以防止资源的同时更新相互覆盖（“空中碰撞”）

如果给定URL中的资源更改，则一定要生成新的Etag值。比较etags能快速确定此资源是否变化，但也可能被跟踪服务器永久存留。

指令

- 'W/'表示使用弱验证器。弱验证器很容易生成，但不利于比较
- "<**etag-value**>"实体标签唯一表示所请求的资源。没有明确的算法实现，通常可以使用内容的散列，最后修改时间戳的哈希值，或简单的使用版本号方式

**避免“空中碰撞”**- 使用Etag和If-Match头部实现

**缓存未更改的资源**-通过Etag和If-None-Match比较实现。1.用户再次访问给定的URL（设有ETag字段），显示资源过期了且不可用，客户端就发送值为ETag的IF-None-Match header字段 2.服务端将客户端的ETag与其当前版本的资源的ETag进行比较，如果两个值匹配，服务器将返回不带任何内容的304未修改状态，告诉客户端缓存版本可用

33. Expect：是一个请求消息头，包含一个期望条件，表示服务器只有在满足此期望条件的情况下才能妥善处理请求。

34. Expires：响应头包含日期/时间，即在此时候之后，响应过期（http1.1）

如果在Cache-Control响应头中设置了"max-age"或者"s-max-age"指令，那么Expires头会被忽略

35. Forwarded：包含了代理服务器的客户端的信息，即由于代理服务在请求路径中的接入而被修改或丢失的信息。可以用X-Forwarded-For、X-Forwarded-Host、X-Forwarded-Proto替换。会暴露一定的隐私和敏感信息，比如客户端的IP地址。

```
Forwarded: by=<identifier>; for=<identifier>; host=<host>; proto=<http|https>
```

Identifier - 显示在使用代理的过程中被修改或者丢失的信息。

- 一个IP地址（V4或V6，ipv6地址需要包含在方括号里面，同时用括号括起来）
- 语意不明的标识符（比如“_ hidden”或“_ secret”）
- "unknown"，当前信息实体不可知

by - 请求进入到代理服务器的接口

for - 发起请求的客户端以及代理链中的一系列的代理服务器

host - 代理接收到的Host首部的信息

proto - 发起请求时采用的何种协议，通常是"http"或者"https"

```
# 大小写不敏感
Forwarded: For="[2001:db8:cafe::17]:4711"

# for proto by 之间可用分号分隔
Forwarded: for=192.0.2.60; proto=http; by=203.0.113.43

# 多值可用逗号分隔
Forwarded: for=192.0.2.43, for=198.51.100.17
```

36. Host：指名了服务器的域名，以及（可选的）服务器监听的TCP端口号。如果没有给定端口号，会自动使用被请求服务的默认端口（一般为80）HTTP1.1的所有请求报文中**必须包含**一个Host头字段。如果一个HTTP1.1请求缺少Host头字段或者设置了超过一个的Host头字段，会返回400状态码

37. If-Match：表示是一个条件请求。在请求方法为GET和HEAD的情况下，服务器仅在请求的资源满足此首部列出的ETag之一时才会返回资源。而对于PUT或其他非安全方法来说，只有在满足条件的情况下才可以将资源上传

38. If-Modified-Since：条件式请求首部，服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为200。如果请求的资源从那时未修改，那么返回一个不带有消息主体的304响应，而在**Last-Modified**首部中会带有上次修改时间。该**请求参数只会在GET或者HEAD请求中使用**

当与If-None-Match一同出现时，会被忽略掉，除非服务器不支持If-None-Match

39. If-None-Match：表示是一个条件请求。对于GET和HEAD请求方法，当且仅当服务器上没有任何资源的ETag属性值与这个首部中列出的相匹配的时候，服务器端才会返回请求的资源，响应码200。对于其他方法来说，当且仅当最终确认没有已存在的资源的  [`ETag`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/ETag) 属性值与这个首部中所列出的相匹配的时候，才会对请求进行相应的处理。

40. If-Range：HTTP请求头字段用来使得Range头字段在一定条件下起作用：当字段值中的条件得到满足时，Range头字段才会起作用，同时服务器回复**206**部分内容状态码，以及Range头字段请求的响应部分；如果字段值中的条件没有得到满足，服务器将会返回200状态码，将返回完整的请求资源

If-Range头字段通常用于断点续传的下载过程中，用来自从上次中断后，确保下载的资源没有发生改变

```
If-Range: <星期>, <日> <月> <年> <时>:<分>:<秒> GMT
If-Range: <etag>
```

41. If-Unmodified-Since：用于请求中，使得当前请求称为条件式请求：只有当资源在指定的时间之后没有进行过修改的情况下，服务器才会返回请求的资源，或是接受POST或其他non-safe方法的请求。如果所请求的资源在指定的时间之后发生了修改，那么会返回412错误

应用场景：

- 与non-safe方式如POST搭配使用，可以用来优化并发控制
- 与含有If-Range消息头的范围请求搭配使用，用来确保新的请求片段来自于未经修改的文档

42. Keep-Alive（非标准）：允许消息发送者暗示连接的状态，还可以用来设置超时时长和最大请求数

43. Large-Allocation(非标准)：用来告诉浏览器加载该页面可能需要申请大内存。当前只有Firefox实现。WebAssembly或者asm.js会使用比较大的连续内存空间。Large-Allocation告诉浏览器将要加载的页面可能需要申请一个大的连续内存空间，浏览器依据该头部可能会单独启动一个专有的进程用于处理该页面

指令：0- 是一个特殊值，代表分配的大小不确定（动态允许） <**megabytes**>- 预期需要申请的内存大小，以M为单位

44, Last-Modified：响应首部，包含源头服务器认定的资源作出修改的日期及时间。

45. Location：首部指定的是需要将页面重新定向至的地址（状态码为303、307、308、301、302）或者新创建的文件的URL（状态为201）。一般在响应码为3XX的响应中才会有意义

46. Origin：请求首部，指示请求来自于哪个站点。该字段指示服务器名称，并不包含任何路径信息。该首部用于**POST**或者**CORS**请求

47. Proxy-Authenticate：响应首部，指定了获取proxy server（代理服务器）上的资源访问权限而采用的身份验证方式。代理服务器对请求进行验证，以便进一步传递请求。

48. Proxy-Authentization：请求首部，其中包含了用户代理提供给代理服务器的用于身份验证的凭证

49. Range：请求首部，告知服务器返回文件的哪一部分。在一个Range首部中，可以一次性请求多个部分，服务器会以multipart文件的形式将其返回。如果服务器返回的是范围响应，需要使用206状态码。

```
Range: <unit>=<range-start>-
Range: <unit>=<range-start>-<range-end>
Range: <unit>=<range-start>-<range-end>, <range-start>-<range-end>
Range: <unit>=<range-start>-<range-end>, <range-start>-<range-end>, <range-start>-<range-end>
```

50. Referer：包含了当前请求页面的来源页面的地址，即表示当前页面是通过此来源页面里的链接进入的。服务端一般用该首部识别访问来源。

```
Referer首部可能暴露用户的浏览历史，涉及到用户的隐私问题
```

在以下两种情况下，Referer不会被发送：

- 来源页面采用的协议为表示本地文件的 "file" 或者 "data" URI；
- 当前请求页面采用的是非安全协议，而来源页面采用的是安全协议（HTTPS）

51. Referrer-Policy：用来监管哪些访问来源信息—会在Referer中发送—应该被包含在生成的请求当中

指令：

- no-referrer- 整个referer首部会被移除
- no-referrer-when-downgrade（默认值）- 在没有指定任何策略的情况下用户代理的默认行为。在同等安全级别的情况下，引用页面的地址会被发送（HTTPS -> HTTPS），但是在降级的情况下不会被发送（HTTPS->HTTP）
- origin- 在任何情况下，仅发送**文件的源**作为引用地址
- origin-when-cross-origin- 对于**同源的请求**，会发送**完整的URL**作为引用地址，但是对于**非同源请求**仅发送**文件的源**
- same-origin- 对于同源的请求会发送引用地址，非同源不会发送
- strict-origin- 在同等安全级别的情况下，发送文件的源作为引用地址，降级的情况不会发送
- strict-origin-when-cross-origin- 对于同源的请求，会发送完整的URL作为引用地址；在同等安全级别的情况下，发送文件的源作为引用地址；在降级的情况下不发送此首部
- unsafe-url- 无论是同源请求还是非同源请求，都发送完整的URL作为引用地址

例子[https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Referrer-Policy](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Referrer-Policy)

52. Retry-After：响应首部，表示用户代理需要等待多长时间之后才能继续发送请求

- 当与503（当前服务不存在）响应一起发送的时候，表示服务下线的预期时长
- 当与重定向响应一起发送的时候，如301（永久迁移），表示用户代理在发送重定向请求之前需要等待的最短时间

53. Set-Cookie：响应首部，被用来由服务器向客户端发送cookie

指令：

**Expires**=<**date**> cookie的最长有效时间，形式为符合HTTP-date规范的时间戳。如果没有设置这个属性，表示是一个**会话期cookie**

**Max-Age**=<**non-zero-digit**> 在cookie失效之前需要经过的秒数。老的浏览器（ie6 7 8）不支持这个属性。Expires和Max-Age同时存在，Max-Age优先级更高

**Domain**=<**domain-value** > 指定cookie可以送达的主机名

**Path**=<**path-value**> 指定一个URL路径，这个路径必须出现在要请求的资源的路径中才可以发送Cookie首部。如果path=/docs，那么"/docs"，"/docs/Web/"或者"/docs/Web/HTTP"都满足匹配的条件

**Secure** 只有在请求使用SSL和HTTPS协议的时候才会被发送到服务器

**HttpOnly** 设置了HttpOnly属性的cookie不能使用Javascript经由Document.cookie属性、XMLHttpRequest和Request API上进行访问，防范跨站脚本攻击（XSS）

**SameSite**=**Strict/Lax** 设置后cookie不随跨域请求一起发送，一定程度上防范跨站请求伪造攻击（CSRF）

54. SourceMap HTTP响应头连接生成的代码到一个source map，使浏览器能够重建原始的资源然后显示在调试器里

55. User-Agent 首部包含了一个特征字符串，用来让网络协议的对端来识别发起请求的用户代理软件的应用类型、操作系统、软件开发商以及版本号

```
User-Agent: <product> / <product-version> <comment>
```

```
Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0
Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0
```

56. Vary 响应头，决定了对于未来的一个请求头，应该用一个缓存的回复（response）还是向源服务器请求一个新的回复

## HTTP权威指南

### 概述

Web服务器是Web资源(Web resource)的宿主。Web资源是Web内容的源头。最简单的Web资源就是Web服务器文件系统中的静态文件。还可以包含：文本文件、HTML文件、微软的Word文件、Adobe的Acrobat文件、JPEG图片文件、AVI电影文件，或所有其他能够想到的格式。

#### URI

服务器资源名被称为统一资源标识符（Uniform Resource Identifier, URI）。URI有两种方式，分别称为URL和URN

#### URL

**统一资源定位符(URL)**是资源标识符最常见的形式。URL描述了一台特定服务器上某资源的特定位置。

大多数URL方案的URL语法都建立在由9部分构成的通用格式上：

```
<scheme>://<user>@<password>:<host>:<port>/<path>;<params>?<query>#<frag>
```

但最重要的3个部分是**方案(scheme)**，**主机(host)**，**路径(path)**

**参数(params)**：某些方案会用这个组件来指定输入参数。参数为键/值对。URL中可以包含多个参数字段，它们相互之间以及与路径的其余部分之间用分号(;)分隔

**片段(frag)**：引用对象时，不会将frag字段传送给服务器；这个字段是在客户端内部使用的。通过字符"#"将其与URL的其余部分分隔开来

#### URN

**统一资源名(URN)**是作为特定内容的唯一名称使用的，与目前的资源所在地无关。通过URN，还可以用同一个名字通过多种网络访问协议来访问资源。

### 事务

一个HTTP事务由一条（从客户端发往服务器的）请求命令和一个（从服务器发回客户端的）响应结果组成。这种通信是通过名为HTTP报文（HTTP message）的格式化数据块进行的。

### 报文

HTTP报文是由一行一行的简单字符串组成的。HTTP报文都是纯文本，不是二进制代码。

HTTP报文包括三个部分：

- 起始行

  报文的第一行就是起始行，在请求报文中用来说明要做什么，在响应报文中说明出现了什么情况

- 首部字段

  起始行后面有零个或多个首部字段。首部以一个空行结束。

- 主体

  空行之后就是可选的报文主体，其中包含了所有类型的数据。**请求主体中包括了要发送给Web服务器的数据；响应主体中装载了要返回给客户端的数据。**主体中可以包含任意的二进制数据(比如图片、视频、音轨、软件程序)。

### Web的结构组件

#### 代理

HTTP代理服务器，这是Web安全、应用集成以及性能优化的重要组成模块。

出于安全考虑，通常会将代理作为转发所有Web流量的可信任中间节点使用。代理还可以对请求和响应进行过滤。

#### 缓存

Web缓存(Web cache)是一种特殊的HTTP代理服务器，可以将经过代理传送的常用文档复制保存起来。

#### 网关

网关(gateway)是一种特殊的服务器，**作为其他服务器的中间实体使用**。通常用于将HTTP流量转换成其他的协议。网关接收请求时就好像自己是资源的源端服务器一样。

#### 隧道

隧道(tunnel)是建立起来之后，就会在两条连接之间对原始数据进行盲转发的HTTP应用程序。HTTP隧道通常用来在一条或多条HTTP连接上转发非HTTP数据，转发时不会窥探数据。

HTTP隧道的一种常见用途是通过HTTP连接承载加密的安全套接字层(SSL)流量，这样SSL流量就可以穿过只允许Web流量通过的防火墙了。

#### Agent代理

用户Agent代理(或者简称为Agent代理)是代表用户发起HTTP请求的客户端程序。所有发布Web请求的应用程序都是HTTP Agent代理。比较常说到的HTTP Agent代理是Web浏览器。但除了这个，还有些自动用户Agent代理，比如"网络蜘蛛"(spiders)或者"Web机器人"(Web robots)。

### URL与资源

#### URL编码

为了避开安全字符集表示法带来限制，设计了一种编码机制，用来在URL中表示各种不安全的字符。这种编码机制就是通过一种"转义"表示法来表示不安全字符的，这种转义表示法包含一个百分号(%)，后面跟着两个表示字符ASCII码的十六进制数。

在URL中，有几个字符被保留起来，有着特殊的含义。在将其用于保留用途之外的场合时，要在URL中对其进行编码。包括：

- % - 保留作为编码字符的转义字符
- / - 保留作为路径组件中分隔路径段的定界符
- . - 保留在路径组件中使用
- .. - 保留在路径组件中使用
- \# - 保留作为分段定界符使用
- ? - 保留作为查询字符串定界符使用
- ; - 保留作为参数定界符使用
- : - 保留作为方案、用户/口令，以及主机/端口组件的定界符使用
- $,+ - 保留
- @ & = - 在某些方案的上下文中有特殊的含义，保留
- { } | \ ^ ~ [ ] ' - 由于各种传输Agent代理，比如各种网关的不安全处理，使用受限
- < > " - 不安全
- 0x00-0x1F,0x7F - 受限这些十六进制范围内的字符都在US-ASCII字符集的不可打印区间内
- \> 0x7F - 受限，十六进制值不在US-ASCII字符集的7比特范围内

### HTTP报文

#### 报文流

**这是形容http报文的**

- http报文是以一种类似的流的方式来发送数据的，所以报文流讲述了http报文的一些客观状态，相关术语：流入、流出形容事务处理。http报文任何时候是从上游向下游流入的！其中进过的节点既可能是上游，有可能是下游，如果从某个节点流出，那么相对于此节点流入的那个节点，它就是上游，反过来它就是下游！

#### 报文的组成部分

每条报文都包含一条来自客户端的请求，或者一条来自服务器的响应。由三部分组成：起始行(start line)、包含属性的首部(header)块、以及可选的、包含数据的主体(body)部分。

每行都以一个由两个字符组成的行终止序列作为结束，其中包括一个回车符和一个换行符，写做**CRLF**。

http报文分为请求报文和相应报文，其语法分别如下：

```
//请求报文

<method> <request-URL> <version>
<headers>

<entity-body>

//响应报文

<version> <status> <reason-phrase>
<headers>

<entity-body>
```

```
方法是客户端希望执行的动作，如GET、POST等

请求url是指请求资源的路径

http版本号，格式为http/<major>.<minor>,分别代表主要版本号和次要版本号，其含义应分开理解

status code其实说白了就是用一个数字表示当前事务处于什么状态，便于开发者处理

原因短语，实际意义不大，就是为了方便人看的

首部就是一个包含零个或多个的键值对，键值对以crlf隔开，而键、值之间以‘:’隔开，期间包含一个可选的空格

主体任意格式组成的数据块，也是实际发送的内容
```

##### 方法

- GET方法用于请求服务器端发送某个资源
- HEAD方法跟GET方法类似，区别就是不返回主体
- PUT方法用于向服务器端修改、插入数据
- POST方法用于向服务器端发送数据
- TRACK方法用于向服务器端请求报文在发送的过程中经过了什么修改，主要用于测试
- OPTIONS用于请求服务器告知其支持什么功能
- DELETE用于向服务器删除某个指定的资源
- 扩展方法其实类似于自定义方法

##### 状态码

- 100-199 信息性状态码
- 200-299 成功状态码 （常见200表示请求成功）
- 300-399 重定向状态码 （常见302重定向）
- 400-499 客户端错误状态码 （常见404，请求资源不存在）
- 500-599 服务端错误状态码

### 连接管理

> TCP/IP的一些知识：TCP/IP建立连接会做哪些事情，带来的时延。提升性能的方法，包括串行连接、并行连接、持久链接、管道连接等。

#### TCP连接

客户端应用程序可以打开一条TCP/IP连接，连接到可能运行在任何地方的服务器应用程序。一旦连接建立起来，在客户端和服务器的计算机之间交换的报文就永远不会丢失、受损或失序。

**当键入一个URL时，HTTP会发生哪些事情？**

1. 浏览器从地址栏中解析处域名（主机名），也就是拿到www.xxx.com
2. 浏览器根据得到的主机名查询出ip地址，如x.x.x.x，（中间可能经过查找host文件或去查询dns服务器）
3. 浏览器解析出端口（http默认为80，https默认为443）
4. 浏览器发起一条到x.x.x.x端口为80的链接，（重建需要经过几次确定相关参数的来回“握手”）
5. 浏览器发起请求报文
6. 服务器返回响应报文
7. 浏览器关闭连接（其实浏览器和服务器都可以在不通知对方的情况关闭连接）

TCP的数据是通过名为IP分组(或IP数据报)的小数据块来发送的。HTTP要传送一条报文时，会以留的形式将报文数据的内容通过一条打开的TCP连接按序传输。TCP收到数据流之后，会将数据流分成被称作段的小数据块，并将段封装在IP分组中，通过因特网进行传输。

每个IP分组中都包括：

- 一个IP分组首部(通常为20字节)
- 一个TCP段首部(通常为20字节)
- 一个TCP数据块(0个或多个字节)

TCP是通过端口号来保持所有这些连接持续不断地运行。

TCP用四个信息来唯一确定一条连接：源ip地址、源端口号、目的ip地址、目的端口号。只要其中有一个不同，那么就不是同一条连接。在任意时刻计算机都可以有几条tcp连接在打开状态。

TCP编程接口，提供了一套完整的套接字API。向HTTP程序员隐藏了TCP和IP的所有细节。套接字API允许用户创建TCP的端点数据结构，将这些端点与远程服务器的TCP端点进行连接，并对数据流进行读写。

#### 对TCP性能的考虑

与建立TCP连接，以及传输请求和响应报文的时间相比，事务处理时间可能是很短的。除非客户端或服务器超载，或正在处理复杂的动态资源，否则HTTP时延就是由TCP网络时延构成的。

HTTP事务的时延主要原因：

1. 首先客户端解析ip地址或者端口号需要时间，如果当前没有访问过相关资源，那么解析还需要查询dns服务器，此操作，造成的时延较多，可能花费数十秒。
2. 建立tcp链接会有建立时延，通常2s左右，如果当前的http事务较多，那么会很快叠加上去。
3. 传输、处理请求报文需要时间
4. 回传响应报文需要时间
5. 当然还有其他因素，比如硬件、网络负载，以及报文尺寸等！

TCP相关时延其中包括：

- TCP连接建立握手

- TCP慢启动拥塞控制

- 数据聚集的Nagle算法

  Nagle算法试图在发送一个分组之前，将大量TCP数据绑定在一起，以提高网络效率。该算法鼓励发送全尺寸(LAN上最大尺寸的分组大约是**1500字节**)的段。但该算法会带来几个HTTP性能问题：小的HTTP报文可能无法填满一个分组，可能会因为等待那些永远不会到来的额外数据而产生时延。Nagle算法与延迟确认之间的交互存在问题—Nagle算法会阻止数据的发送，直到有确认分组抵达为止，但确认分组自身会被延迟确认算法延迟100-200毫秒。

  一般设置**TCP_NODELEY**，禁用Nagle算法提高性能

- 用于捎带确认的TCP延迟确认算法

  每个TCP端都有一个序列号和数据完整性校验和。每个段的接受者收到完好的段时，都会向发送者回送小的确认分组。由于确认报文很小，所有TCP允许在发往相同方向的输出数据分组中对其进行"捎带"。为了增加确认报文找到同向传输数据分组的可能性，很多TCP栈都实现了一种"延迟算法"。会在一个特定的窗口时间(通常是100-200毫秒)内将输出确认存放在缓冲区中，以寻找能够捎带它的输出数据分组。如果在那个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送

- TIME_WAIT时延和端口耗尽

  当某个TCP端口关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近所关闭连接的IP地址和端口号。通常是所估计的最大分段使用期的两倍。**这个算法可以防止在两分钟内创建、关闭并重新创建两个具有相同IP地址和端口号的链接。**

#### HTTP连接的处理

##### Connection

两个相邻的HTTP应用程序可以共享只需要他们二者的选项，可以通过Connection来传递，这个首部字段可以通过逗号分隔传递连接标签列表，并且这些标签不会传播到其他连接中去，会在这个连接中就删除。除了Connection首部有这个特性以外，还包括Proxy-Authenticate、Proxy-Connection、Transfer-Encoding和Upgrade。

Connection首部可以承载三种字段值：

- HTTP首部字段名(如Keep-Alive)，列出了只与此连接有关的首部
- 任意标签值，用于描述此连接的非标准选项
- 值close，说明操作完成之后需关闭这条持久连接

##### 串行连接

此种机制描述了http事务一个一个接着发起，不能同时下载更多的资源，使得界面上用户看不到东西，体验不够好。串行连接没有很好的利用tcp/ip连接的慢启动机制！

优化方法：

- 并行连接

  浏览同时发起过个http事务，因为是并行的，所以时延也并行的，这样总时延较小，页面呈现更快，体验较好。但也不是总是这样，因为如果在网络速度很慢的时候，多个连接会去竞争本来不多的带宽，那么就谈不上加快速度了。还有就是并行连接也是需要付出代价的，比如增加系统内训消耗、服务器负载，比如有一个100客户端同时对服务发起100tcp并行连接的话，那么服务器就得负责10000个处理请求，很快的你的服务器就会爆掉。当然了，并行连接确实能带来视觉上的速度提升，因为相比于串行连接慢慢地显示数据而并行一下子能全部显示完信息，视觉上并行连接会给人速度更快的感觉。

  浏览器使用了并行连接，但他们会将并行连接的总数限制为一个较小的值（**通常是6个**）。

- 持久连接

  包括两种情况：

  - HTTP/1.0+ keep-alive连接

    客户端需要在链接中包含Connection: Keep-Alive首部请求，将连接保持在打开状态。此时服务器在响应中也会包含相同的首部。**如果响应中没有Connection: Keep-Alive首部，客户端就认为服务器不支持keep-alive，会在响应报文之后关闭连接**。

    当设置完Connection: Keep-Alive首部之后，可以设置Keep-Alive选项的值：

    - timeout - 估计服务器希望将连接保持在活跃状态的时间，但不是承诺值
    - max - 估计服务器希望为多少个事务保持此连接的活跃状态，但不是承诺值
    - 任意未经处理的属性，主要用于诊断和调试，语法为name [=value]

    **Keep-Alive和哑代理会产生一些特殊的问题！**哑代理只会盲目的转发客户端发送的请求中的所有首部，不会去除connection首部，导致服务器返回带有connection: Keep-Alive首部给客户端，服务器不会关闭连接，代理始终被挂起等待关闭，客户端发送新的请求，代理不认请求，导致被忽略，直至超时，并将其关闭为止。

    使用**Proxy-Connection: Keep-Alive解决客户端和服务端之间只有一个代理的情况的哑代理问题**。哑代理不会识别Proxy-Connection，但Connection没有设置，所以不会有问题；能识别Proxy-Connection的代理，会把Proxy-Connection的值赋给Connection，使得在传输过程中不会关闭连接。但对于大于一个代理的情况又变得没有意义了。

  - HTTP/1.1 persistent连接

    默认情况下是激活的。可以通过显示的添加Connection: close关闭连接。但是不发送这个首部也是可以关闭的。

- 管道化连接

  HTTP1.1允许在持久连接上可选地使用请求管道。在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向另一端的服务器时，第二条和第三条请求也可以开始发送。

- 复用的连接

#### 关闭连接的奥秘

所有HTTP客户端、服务器或代理都可以任意时刻关闭一条TCP传输连接。

HTTP响应都应该有精确的Content-Length首部，用以描述响应主体的尺寸。如果在响应关闭结束时，实际传输的实体长度与Content-Length并不匹配(或没有Content-Length)时，接收端就应该质疑。

如果接收端是缓存代理，接收端不能缓存不匹配的响应。

如果一个事务、不管是执行一次还是很多次，得到的结果都是相同，这个事务就是幂等的。GET、HEAD、PUT、DELETE、TRACE和OPTIONS都具有这个特性。客户端不应该以管道化方式传送非幂等请求（比如POST）。

关闭分两种：

- 完全关闭 - 套接字调用close()会将TCP连接的输入和输出信道都关闭
- 半关闭 - 套接字调用shutdown()会单独关闭输入或输出信道

关闭连接是有学问的。

**关闭连接的输出信道总是安全的**。连接的另一端的对等实体会在从器缓冲区中读出所有数据之后收到一条通知，说明流结束了，这样它就知道将连接关闭了。

**关闭连接的输入信道比较危险**。如果另一端向你已关闭的输入信道发送数据，操作系统就会向另一端机器回送一条TCP"连接被对端重置"的报文，会导致的问题比较严重，即删除对端还未读取的所有缓存数据。例如，传输了10条请求都已经接收到缓存中，但第11条因为关闭了输入信道，导致前面的10条缓存都被删除。

总之，实现正常关闭的应用程序首先应该关闭它们的输出信道，然后等待连接另一端的对等实体关闭它的输出信道。当两端都告诉对方它们不会再发送任何数据(比如关闭输出信道)之后，连接就会被完全关闭，而不会有重置的危险。

但也无法确保对等实体会实现半关闭，或对其进行检查。但是要关闭输出信道，然后周期性地检查其输入信道的状态(查找数据，或流的末尾)。如果在一定的时间区间内对端没有关闭输入信道，应用功能程序可以强制关闭连接，以节省资源。

### Web服务器

Web服务器实现了HTTP和相关的TCP连接处理。负责管理Web服务器提供的资源，以及对Web服务器的配置、控制及扩展方面的管理。

Web服务器逻辑实现了HTTP协议、管理着Web资源，并负责提供Web服务器的管理功能。Web服务器逻辑和操作系统共同负责管理TCP连接。底层操作系统负责管理底层计算机系统的硬件细节，并提供了TCP/IP网络支持、负责装载Web资源的文件系统以及控制当前计算活动的进程管理功能。

#### web服务器应该做些什么

1. 接受建立连接请求
2. 接受请求
3. 处理请求
4. 访问报文中指定的资源
5. 构建响应
6. 发送响应
7. 记录事务处理过程

#### 第一步————接受客户端连接

- 客户端收到一条连接之后，那么它将会把新连接添加到现存web服务器连接列表中，用于监视当前连接上的数据传输情况。
- 通过ident确认客户端用户。服务器可以通过ident协议**找到发起HTTP连接的用户名**。客户端如果支持ident协议，就在TCP端口113上接听ident请求。但ident在公共英特网上并不能很好的工作，因为：
  - 很多客户端PC没有运行ident识别协议守护进程软件
  - ident协议会使HTTP事务处理产生严重的时延
  - 防火墙不允许ident流量进入
  - ident协议不安全
  - ident不支持虚拟IP地址
  - 暴露客户端的用户名涉及隐私问题

#### 第二步————接收请求报文

- 主要经过几个步骤来解析报文：

1. 解析请求行，得知方法、url、协议版本，各项之间由一个空格分隔，并以回车换行(CRLF)序列作为行的结束
2. 解析得到以CRLF结尾的首部
3. 得到以CRLF结尾，标志首部结束的空行（如果有的话）
4. 解析得到主体（如果有的话）

- web服务可能还会把请求报文用一种自己能快速处理的内部数据结构来存储请求报文
- 不同的服务器配置预示它能同时处理的事务情况：

1. 单线程web服务器：只能处理一个请求，待当前请求处理完成之后才能处理下一个请求。优点：简单已于实现，适用于低负荷服务器。缺点：不能及时处理其他请求，容易引发延迟过长而导致性能问题。
2. 多线程及多进程web服务器：能同时处理多个请求。优点：响应及时。缺点：构建复杂，容易快速引起内存消耗过大而死机。最好应该对能同时处理的连接数量进行限制。
3. 复用i/o的web服务器：只有在有事情可做时才会对连接进行处理；在空闲连接上等待的时候并不会绑定线程和进程。
4. 复用i/o和多线程的web服务器：2和3的结合

#### 第三步————处理请求

#### 第四步————对资源的映射及访问

- 最简单的资源映射形式就是用请求URI作为名字来访问Web服务器文件系统中的文件。通常，Web服务器的文件系统中会有一个特殊的文件夹专门用于存放Web内容。这个文件夹被称为docroot(文档根目录)。但不能让相对URL退到docroot之外，将文件系统的其余部分暴露出来，也就是不允许访问根目录的上一级目录，如http://www.joes-hardware.com/../。
- 虚拟托管的docroot:在一个服务器上挂了几个web站点，那么这样当请求的资源路径相同时，服务器应该从请求报文首部的host、uri字段找出真正的资源目录，这些目录都是可以配置的。

#### 第五步————构建响应

- 构建响应报文：1、正确设置响应主体的长度（content-length）；2、设置报文的mime类型（content-type）,主要通过与一直mime类型文件匹配得到当前的文件的mime类型，还可以通过文件扩展名，以及硬规定特定目录下的文件拥有某个mime类型；3、控制重定向
- 服务器端如何得出文件的MIME类型：

```
Web服务器要负责确定响应主体的MIME类型。有很多配置服务器的方法可以将MIME类型与资源关联起来。

1、MIME类型（mime.types）
Web服务器可以用文件的扩展名来说明MIME类型。Web服务器会为每个资源扫描一个包含了所有扩展名的MIME类型的文件，以确定其MIME类型。这种基于扩展名的类型相关是最常见的！

2、魔法分类（Magic typing）
Apache Web服务器可以扫描每个资源的内容，并将其与一个已知模式表（被称为魔法文件）进行匹配，以决定每个文件的MIME类型。这样做可能比较慢，但很方便，尤其是文件没有标准扩展名的时候。

3、显示分类（Explicit typing）
可以对Web服务器进行配置，使其不考虑文件的扩展名或内容，强制特定文件或目录内容拥有某个MIME类型

4、类型协商
有些Web服务器经过配置，可以以多种文档格式来存储资源。在这种情况下，可以配置Web服务器，使其可以通过与用户的协商来是决定使用哪种格式（及相关的MIME类型）“最好”。
```

##### 重定向

- 有时服务器需要返回重定向报文来构建响应，重定向响应由返回码3XX说明。Location响应首部包含了内容的新地址或优选地址的URL。重定向可用于下列情况。
  - 永久删除的资源，状态码为301
  - 临时删除的资源，状态码为303或307
  - URL增强，状态码为303或307
  - 负载均衡，主要是减少服务器的压力，让请求跑到一个负载不大的服务器上去，状态码为303或307
  - 服务器关联，去保存有用户本地信息的服务器上获取用户信息，状态码为303或307
  - 规范目录名称，客户端请求的URI是一个不带尾部斜线的目录名时，大多数Web服务器都会将客户端重定向到一个加了斜线的URI上，这样相对链接就可以正常工作了！

#### 第六步————发送响应

#### 第七步————记录事务日志

- 在web服务器日志文件中添加一个条目，以描述当前事务处理情况

### 代理

Web代理(proxy)服务器是网络的中间实体。代理位于客户端和服务器之间，扮演"中间人"的角色，在各端点之间来回传送HTTP报文。HTTP的代理服务器既是Web服务器又是Web客户端。

代理服务器可以是某个客户端专用的，也可以是很多客户端共享的。单个客户端专用的代理被称为私有代理。众多客户端共享的代理被称为公共代理。

#### 代理与网关的对比

- 代理连接的是两个或多个使用相同协议的应用程序
- 网关连接的是两个或多个使用不同协议的端点，网关扮演的是"协议转换器"的角色，即使客户端和服务器使用的是不同的协议，客户端也可以通过它完成与服务器之间的事务处理

现在代理和网关之间的区别比较模糊。商业化的代理服务器也要实现网关的功能来实现SSL安全协议，SOCKS防火墙、FTP访问，以及基于Web的应用程序。

#### 为什么使用代理

- 改善安全性
- 提高性能
- 节省费用
- 可以看到并接触到所有流过的HTTP流量，可以监视流量并对其进行修改，以实现很多有用的增值Web服务
  - 儿童过滤器 - 如服务器响应的成人内容进行过滤
  - 文档访问控制 - 验证客户端访问某个的文件需要的证书
  - 安全防火墙 - 提供一个防火墙保护客户端或服务器
  - Web缓存 - 对客户端响应资源的副本，节省带宽、减少网络拥堵
  - 反向代理 - （原始服务的替代物，能访问其他服务器，作服务器加速器使用）伪装成原始服务器，不过与服务器不同的是反向代理还可以向其他服务器发送请求，以便实现按需定位所请求的内容
  - 内容路由器 - 根据因特网流量状况以及内容类型将请求导向特定的Web服务器
  - 转码器 - 可以修改内容的主体格式
  - 匿名者 - 主动从HTTP报文中删除身份特性（比如客户端IP地址、From首部、Referer首部、cookie、URI的会话ID），从而提供高度的私密性和匿名性

#### 代理服务器的部署

根据目标用途，可以将代理放在任意位置：

1. 出口代理：部署在本地网络端，用于保护本地网络或者限制公司带宽
2. 访问（入口）代理：用于实现提供缓存响应
3. 反向代理：通常被部署在网络边缘，在Web服务器之前，作为替代物使用。从而提高Web服务器安全特性，或者将快速的Web服务器缓存放在较慢的服务器之前，以提高性能
4. 网络交换代理：部署在网络上，通过缓存来减轻因特网节点的拥塞，并对流量进行监视

#### 代理如何获取流量

1. 修改客户端：比如现在的客户端都支持收手动和自动配置代理
2. 修改网络：网络通过一些技术在客户端不知情的情况揽入流量进入代理，这种代理被称为拦截代理
3. 修改DNS命名空间：把主机名映射为代理的ip地址，比如修改系统的DNS映射文件，让代理伪装成原始服务器，从而把web请求导入代理
4. 修改服务器：让服务器返回一个重定向有关的代码，把http请求报文导入到代理

#### 客户端代理设置

主要介绍客户端配置代理的几种常见方式，如下：

- 手工配置 : 显示地设置要使用的代理

- 预先配置浏览器 : 浏览器厂商或发行商会在将浏览器发送给其客户之前预先对浏览器（或所有其他的Web客户端）的代理设置进行手工配置
- 代理的自动配置（Proxy Auto-Configuration,PAC）：一个代理配置的js文件，客户端在请求之前会取回这个js文件，从而判断如何决定使用代理
- WPAD的代理发现 : Web代理自动发现协议(Web Proxy Autodiscovery Protocol, WPAD)，自动检测出浏览器可以从哪个"配置服务器"下载到一个自动配置文件
  - 动态主机配置协议(DHCP)
  - 服务定位协议(SLP)
  - DNS知名主机名
  - DNS SRV记录
  - TXT记录中的DNS服务URI

#### 追踪报文

##### Via首部

Via首部字段列出了与报文途径的每个中间节点（代理或网关）有关的信息。报文每经过一个节点，都必须将这个中间节点添加到Via列表的末尾。

```
Via: 1.1 proxy-62.irenes-isp.net, 1.0 cache.joes-hardware.com
```

Via首部字段用于记录报文的转发，诊断报文循环，标识请求/响应链上所有发送者的协议能力

代理应该在发送一条请求之前，在Via首部插入一个与其自身有关的独特字符串，并在输入的请求中查找这个字符串，以检测网络中是否存在路由循环

###### Via的语法

Via首部字段包含一个由逗号分隔的路标(waypoint)。每个路标都表示一个独立的代理服务器或网关，且包含与那个中间节点的协议和地址有关的信息。

##### TRACE方法

代理服务器可以在转发报文时对其进行修改。为了便于对代理网络进行诊断，需要有一种便捷的方式来观察在通过HTTP代理网络逐条转发报文的过程中，报文是怎样变化的。

当TRACE请求到达目的服务器时，整条请求报文都会被封装在一条HTTP响应的主体中回送给发送端。TRACE响应的Content-Type为message/http。

###### Max-Forwards

可以使用Max-Forwards首部来限制TRACE和OPTIONS请求所经过的代理跳数。Max-Forwards的值如果为零，那么即使接收者不是原始服务器，它也必须将TRACE报文回送给客户端，而不应该继续转发。如果收到的Max-Forwards值大于零，转发的报文中就必须包含一个更新了的Max-Forwards字段，其值会被减一。

### 缓存

#### 缓存的优点

- 缓存减少了冗余的数据传输，节省了网络费用

  每次都从原始服务器拿数据，那么带来的后果就是：多次发送重复的数据浪费流量、耗费昂贵的网络带宽从而降低传输速率、加大服务器的负载。而有了缓存之后这些问题都可以迎刃而解

- 缓存缓解了网络瓶颈的问题

  很多网络为本地客户端配置的带宽要比远程服务器配置的带宽要宽，如果在这种状况下客户端去请求远程服务器，那么客户端将会以一种的较低的速度去请求服务端，从而没有发挥出客户端带宽宽的长处！。如果在客户端方向配置一个高速缓存服务器，那么就可以很快的得到响应，由此也看出带宽对报文传输速率的影响

- 缓存降低了对原始服务器的要求

  一个爆炸性的新闻和热点事件，如果再没有配置缓存的情况下，那么在短时间之内，服务器将会收到突变的请求增长，负荷会爆炸性增长，肯定会吃不消的

- 缓存降低了距离时延

  距离时延说明的一个问题就是传输数据过程这个过程是需要时间的，而且路程越长，那么需要的时间也会越多，即时延越长。所以在距离客户端较近的地方部署缓存服务器，减小了传输路程，那么就减小了传输时延

#### 命中与未命中

可以用已有的副本为某些到达缓存的请求提供服务，被称为缓存命中。其他一些到达缓存的请求可能会由于没有副本可用，而被转发给原始服务器，被称为缓存未命中

缓存对缓存的副本进行再验证时，会向原始服务器发送一个小的再验证请求。如果内容没有变化，服务器会以一个小的304Not Modified进行相应。这被称为再验证命中或缓慢命中。最常用的是If-Modified-Since首部。

#### 缓存的拓扑结构

- 专用缓存被为私有缓存

  Web浏览器中有内建的私有缓存，大多数浏览器都会将常用文档缓存在个人电脑的磁盘和内存中，并且允许用户去配置缓存的大小和各种设置

- 共享缓存被称为公有缓存

代理缓存的层级结构：此种结构描述的以父、子层级出现的层次结构，同时离客户端越近的子缓存的命中率较低（较廉价），他们可以把请求上升到父缓存（较昂贵），从而在父缓存那里实现事务处理

*代理缓存的网状结构*描述的缓存结构并不是很明显呈现父子关系的结构，而是呈无规则的网状。这种结构的思想就是子缓存可以动态选择上一级缓存，从而实现更灵活的缓存控制

#### 缓存的处理步骤

- 接收 - 缓存从网络中读取抵达的请求报文
- 解析 - 缓存对报文进行解析，提取出URL和各种首部
- 查询 - 缓存查看是否有本地副本可用，如果没有，就获取一份副本(并将其保存在本地)
- 新鲜度检测 - 缓存查看已缓存副本是否足够新鲜，如果不是，就询问服务器是否有任何更新
- 创建响应 - 缓存会用新的首部和已缓存的主题来构建一条响应报文
- 发送 - 缓存通过网络将响应发回给客户端
- 日志 - 缓存可选地创建一个日志文件条目来描述这个事务

#### 保持副本的新鲜

HTTP将这些简单的机制称为**文档过期(document expiration)**和**服务器再验证(server revalidation)**

##### 文档过期

通过特殊的HTTP **Cache-Control: max-age**首部(HTTP1.1)和**Expires**首部(HTTP1.0+)，HTTP让原始服务器向每个文档附加一个"过期日期"。二者的区别在于，Cache-Control首部使用的是相对时间而不是绝对日期。

##### 服务器再验证

服务器再验证，说明缓存需要询问原始服务器文档是否发生了变化。最好用的两个首部是**If-Modified-Since**和**If-None-Match**。

- If-Modified-Since，可以与Last-Modified服务器响应首部配合使用
- If-None-Match，服务器可以为文档提供特殊的标签(ETag)

#### 控制缓存的能力

缓存控制能力描述的是服务器可以通过设置相关首部来控制文档的缓存过期时间的能力

- ```
  Cache-Control: no-store //不能缓存
  	
  Cache-Control: no-cache //实际可以存储在本地缓存区中，只是在于原始服务器进行新鲜度再验证之前，缓存不能将其提供给客户端使用
  	
  Cache-Control: must-revalidate //严格遵守新鲜验证规则
  	
  Cache-Control: max-age //设置多长时间的过期时间（相对时间）
  	
  Expires: <date> //设置多长的过期时间（绝对时间）
  ```

### 集成点：网关、隧道及中继

网关可以作为某种翻译器使用，抽象出了一种能够到达资源的方法。网关是资源和应用程序之间的粘合剂。应用程序可以(通过HTTP或其他已定义的接口)请求网关来处理某条请求，网关可以提供一条响应。

有些网关会自动加你HTTP流量转换为其他协议，这样HTTP客户端无需了解其他协议，就可以与其他应用程序进行交互。

网关类型：

- 服务器协议转换器

- 服务器安全网关

- 客户端安全网关

- 应用程序服务器

  最常见的是应用程序服务器，会将目标服务器与网关结合在一个服务器中实现。应用程序服务器是服务器端网关，与客户端通过HTTP进行通信，并与服务器端的应用程序相连

  应用程序服务器并没有回送文件，而是将请求通过一个网关应用编程接口(Application Programming Interface, API)发送给运行在服务器上的应用程序。

#### 隧道

Web隧道(Web tunnel)，可以通过HTTP应用程序访问使用非HTTP协议的应用程序

Web隧道允许通过HTTP连接非HTTP流量，这样就可以在HTTP上捎带其他协议数据。使用Web隧道最常见的原因就是要在 HTTP连接中嵌入非HTTP流量，这类流量就可以穿过只允许Web流量通过的防火墙

Web隧道是用HTTP的CONNECT方法建立起来的。

客户端发送了一条CONNECT请求给隧道网关。客户端的CONNECT方法请求隧道网关打开一条TCP连接。创建TCP连接后，网关就会发送一条HTTP 200响应来通知客户端。此时，隧道建立起来了。客户端通过HTTP隧道发送的所有数据都会被直接转发给输出TCP连接，服务器发送的所有数据都会通过HTTP隧道转发给客户端。

##### CONNECT请求

除了起始行之外，和其他HTTP方法类似。只是后面跟着冒号和端口号的主机名取代了请求URI

```
CONNECT home.netscape.com:443 HTTP/1.0
User-agent: Mozilla/4.0
```

##### CONNECT响应

与普通HTTP响应不同，这个响应并不需要包含Content-Type首部

#### SSL隧道

隧道会通过一条HTTP连接来传输SSL流量，以穿过端口80的HTTP防火墙。

##### SSL隧道与HTTP/HTTPS网关的对比

- 对HTTPS协议进行网关操作：由网关初始化与远端HTTPS服务器的SSL会话，然后代表客户端执行HTTPS事务。响应会由代理接收并解密，然后通过HTTP传送给客户端。很明显，这里存在的问题是客户端到网关之间的链接是普通的非安全HTTP；远端客户端无法对远端服务器执行SSL客户端认证；网关要支持完整的SSL实现
- SSL隧道机制无需在代理中实现。中间的代理服务器只是将加密数据经过隧道传输，并不会在安全事务中扮演其他的角色

#### 中继

中继负责处理HTTP中建立连接的部分，然后对字节进行盲转发。

HTTP很复杂，实现基本的代理功能并对流量进行盲转发，不执行任何首部和方法逻辑，有时是很有用的。但是必须要小心的是，对Connection等首部的处理。会带来潜在的挂起keep-alive连接问题。

### Web机器人

Web机器人是能够在无需人类干预的情况下自动进行一系列Web事务处理的软件程序。很多机器人会从一个Web站点逛到另一个Web站点，获取内容，跟踪超链，并对它们找到的数据进行处理。因此也形象的给他们取了名字，比如"爬虫"、"蜘蛛"、"蠕虫"以及"机器人"。

#### 爬虫及爬行方式

Web爬虫是一种机器人，它们会递归地对各种信息性Web站点进行遍历，获取第一个Web页面，然后获取那个页面指向的所有Web页面，然后是那些页面指向的所有Web页面，以此类推。

爬虫会从根集开始爬行；爬虫会解析页面所有的url，并把他们转换绝对形式；爬行要避免环路的出现，这些环路会带来有害的影响：

- 会使爬虫陷入可能会将其困住的循环之中。会一直兜圈子，把所有时间都好在了不停地获取相同的页面上。会消耗掉很多网络带宽，可能完全无法获取任何其他页面。
- 爬虫不断地获取相同的页面时，另一端的Web服务器也在遭受攻击。会阻止所有真实用户访问这个站点。
- 即使循环自身不是问题，但是爬虫也会获取大量重复的页面。爬虫应用程序最终会被重复的内容所充斥。

网络中两个url表面上看起来不一样，但是指向的是同一资源，那么这两个url就互相称为“别名”，由于别名问题的存在，所以爬虫会爬行重复的数据，所以爬虫有必要把url的进行规范化。如为没有指定端口的主机名添加":80"；将所有转义符%xx都转换成等价字符；删除#标签。但这些操作也只能解决简单的别名问题。因为有些问题在不知道特定Web服务器的相关信息时是没有好办法避免的。

##### 避免循环和重复

- 规范化URL - 将URL转换为标准形式以避免语法上的别名
- 广度优先的爬行 - 以广度优先的方式来调度URL去访问Web站点，就可以将环路的影响最小化。如果采用深度优先方式，一头扎到单个站点中去，就可能会跳入环路，永远无法访问其他站点
- 节流 - 限制一段时间内机器人可以从一个Web站点获取的页面数量
- 限制URL的大小 - 机器人可能会拒绝爬行超出特定长度(通常是1KB)的URL。这种技术肯定会错过一些内容，因为现在很多站点都会用URL来管理用户的状态，使URL的长度变得足够长
- URL/站点黑名单 - 维护一个与机器人环路和陷阱相对应的已知站点及URL列表。发现新问题时，就将其加入黑名单
- 模式检测 - 文件系统的符号连接和类似的错误配置所造成的环路会遵循某种模式，如URL会随着组件的复制逐渐增加
- 内容指纹 - 使用内容指纹的机器人会获取页面内容中的字节，并计算出一个校验和(checksum)。这个校验和是页面内容的压缩表示形式。MD5是常用的指纹计算函数
- 人工监视

#### 机器人的HTTP

在追踪错误爬虫的所有者，以及想服务器提供机器人所能处理的内容类型时，以下信息是很有用的：

- User-agent - 将发起请求的机器人名字告知服务器
- From - 提供机器人的用户/管理者的E-mail地址
- Accept - 告知服务器可以发送哪些媒体类型
- Referer - 提供包含了当前请求URL的文档的URL

虚拟主机需要爬虫带HOST首部，不然会返回错误主机的数据

##### 条件请求

有些机器人实现条件HTTP请求，他们会对时间戳或实体标签进行比较，看看它们最近获取的版本是否已经升级了。这与HTTP缓存查看已获取资源的本地副本是否有效的方法非常相似。

##### 对响应的处理

一般，机器人主要在于用简单的GET方法来获取所请求的内容，所以，一般不会再处理响应的方式上花费太多时间。但是，如果想要更好地探索服务器，机器人应该能对各种不同类型的HTTP响应进行处理

- 状态码 - 机器人至少应该能够处理一些常见的，以及预期的状态码。如200和404
- 实体 - 除了HTTP首部所嵌的信息之外，机器人也会在实体中查找信息。HTML元标签，如http-equiv，就是内容编写者用于嵌入资源附件信息的一种方式

#### 行为不当的机器人

- 失控的机器人，比正常用户的请求速度快很多，当这类爬虫设计出现错误的时候，很容易短时间之内增加服务器的负载，阻止真正用户的访问，原因诸如：编程逻辑错误、陷入环路之中
- 失效的url，url可能已经失效了，但是爬虫依然取请求它 ，这样会让服务器的日志文档里面增加了很多请求出错的记录。
- 很长的错误url,同样请求这样一个url，会让服务器日志文档增加一个很杂论的出错记录
- 爱打听的机器人，访问了一些管理者不允许访问的内容，涉及侵犯隐私
- 动态网关访问

#### 拒绝机器人访问

"拒绝机器人访问标准"，通常只是根据存储访问控制信息的文件而将其称为robots.txt

所有Web服务器都可以在服务器的文档根目录中提供一个可选的、名为robots.txt的文件。这个文件包含的信息说明了机器人可以访问服务器的哪些部分。

如果一个Web站点有robots.txt文件，那么在访问这个Web站点上的任意URL之前，机器人都必须获取它并对其进行处理。由主机名和端口号定义的整个Web站点上仅有一个robots.txt资源。如果是虚拟主机，每个虚拟的docroot都可以有一个不同的robots.txt文件。

如果服务器以404Not Found HTTP状态码进行响应，机器人就可以认为这个服务器上没有机器人访问限制，它可以请求任意的文件。

机器人应在From首部和User-Agent首部中传输标识信息，以帮助站点管理者对机器人的访问进行跟踪。

请求robots.txt是针对服务器返回的状态码，爬虫所作的动作：

- 如果返回2xx代码，机器人就必须对内容进行解析，并使用排斥规则从那个站点上获取内容
- 如果返回404，机器人认为服务器没有激活排斥规则，所以它不受限制
- 如果返回401或403(访问限制)，表示机器人是完全受限的
- 如果返回503（服务器临时故障），那么机器人暂时停止访问，知道正常之后继续请求robots.txt
- 如果返回重定向代码，那么机器人也应该重定向到相关页面

robots.txt文件中有三种类型行：空行、注释行和规则行。

```
User-Agent: slurp
User-Agent: websrawler
Disallow: /private

User-Agent: *
Disallow: 
```

##### HTML的robot-control元标签

可以直接在HTML文档中添加robot-control标签。遵循robot-controlHTML标签规则的机器人仍然可以获取文档，但如果其中有机器人排斥标签，它们都会忽略这些文档。

```
<meta name="robots" content: directie-list>
```

最常用的两个机器人META指令是：

- NOINDEX - 告诉机器人不要对页面的内容进行处理，忽略文档(也就是，不要在任何索引或数据库中包含此内容)
- NOFOLLOW - 告诉机器人不要爬行这个页面的任何外链连接

### HTTP-NG

HTTP发展中至少存在4个方面的问题

- 复杂性 - http相当复杂，而且特性之间是相互依存的
- 可扩展性 - 很难实现递增式扩展
- 性能 - 不好，有些造成时延较大
- 传输依赖性

#### 模块化及功能增强

HTTP-NG工作组建议将协议模块化为三层

- 报文传输层(message transport layer)，不考虑报文的功能，致力于端点间的报文的不透明传输

  报文传输层关心的是报文的有效传输，不考虑报文的含义和目的。报文传输层为报文传输提供了一个API，无论底层实际采用的是什么网络协议栈都可以使用，本层关注的是提高报文传输的功能，包括：

  - 对报文进行管道化和批量化传输，以降低往返时延
  - 重用连接，以降低时延，提高传输带宽
  - 在同一条连接上并行地复用多个报文流，在防止报文流饿死的同时优化共享连接
  - 对报文进行有效的分段，使报文边界的确定更加容易

  WebMUX：是一个复杂的高性能报文系统，可以在一个复用的TCP连接上并行地传输报文。可以对以不同速度产生和消耗的独立报文流进行高效的分组，并将复用到一条或少数几条TCP连接上去

- 远程调用层(remote invocation layer)，定义了请求/响应的功能，客户端可以通过这些功能调用对服务器资源的操作

  本层不关心特定操作的实现及语义(缓存、安全性以及方法逻辑等)；它只关心允许客户端远程调用服务器操作的接口

- Web应用层(Web application layer)，提供了大部分的内容管理逻辑。所有HTTP1.1方法(GET、POST、PUT等)，以及HTTP/1.1首部参数都是在这里定义

### 客户端识别与cookie机制

#### HTTP首部

其中最常见的用来承载用户相关信息的HTTP请求首部：

| 首部名称        | 首部类型 | 描述                                   |
| --------------- | -------- | -------------------------------------- |
| From            | 请求     | 用户的E-mail地址                       |
| User-Agent      | 请求     | 用户的浏览器软件                       |
| Referer         | 请求     | 用户是从这个页面上行依照链接跳转过来的 |
| Authorization   | 请求     | 用户名和密码                           |
| Client-IP       | 请求     | 客户端的IP地址                         |
| X-Forwarded-For | 请求     | 客户端的IP地址                         |
| Cookie          | 请求     | 服务端产生的ID标签                     |

From首部包含了用户的E-mail地址。每个用户都有不同的E-mail地址，所以在理想情况下，可以将这个地址作为可行的源端来识别用户。实际上，From首部是由自动化的机器人或蜘蛛发送的，这样在出现问题时，网关还有个地方可以发送投诉邮件

User-Agent首部可以将用户所用浏览器的相关信息告知服务器，包括程序的名称和版本，通常还包含操作系统的相关信息

Referer首部提供用户来源页面的URL。Referer首部自身并不能完全标识用户，但它确实说明了用户之前访问过哪个页面

#### 客户端IP地址

通常在HTTP首部并不提供客户端的IP滴啊之，但Web服务器可以找到承载HTTP请求的TCP连接另一端的IP地址

使用客户端Ip地址来识别用户存在着很多缺点

- 客户端IP地址描述的是所用的机器，而不是用户
- 很多因特网服务提供商都会在用户登录时为其动态分配IP地址
- 为了提供安全性，并对稀缺的地址资源进行管理，很多用户都是通过网络地址转换(NAT)防火墙来浏览网络内容的
- HTTP代理和网关通常会打开一些新的、到原始服务器的TCP连接。有些代理为了绕过这些问题添加特殊的Client-IP或X-Forwarded-For扩展首部来保存原始的IP地址

#### 用户登录

为了使Web站点的登录更加简便，HTTP中包含了一种内建机制，可以用WWW-Authenticate首部和Authorization首部向Web站传送用户的相关信息

如果服务器希望在为用户提供对站点的访问之前，先行登录，可以向浏览器回送一条HTTP响应代码401Login Required。浏览器会显示一个登录对话框，并用Authorization首部在下一条对服务器的请求中提供这些信息

##### 胖URL

把用户信息添加进url的url称为胖URL，以此来验证用户身份，有存在几个严重的问题

- 丑陋的URL
- 无法共享URL
- 破坏缓存
- 额外的服务器负荷
- 逃逸口，很容易造成用户不小心跳到另一个网站，返回过来的用户的信息全部没了
- 在会话间是非持久的

#### Cookie

分为：

- 会话Cookie(非持久Cookie)
- 持久Cookie

大多数缓存和浏览器都不允许对任何cookie的内容进行缓存

通常会用持久cookie维护某个用户周期性访问的站点的配置文件或登录名

会话cookie和持久cookie之间唯一的区别是**过期时间**。**如果设置了Discard参数，或者没有设置Expires或Max-Age参数来说明扩展的过期时间，这个cookie就是一个会话cookie**。

浏览器内部的cookie罐中可以有成百上千个cookie。但实际上，通常只向每个站点发送2-3个cookie。原因：

- 对所有cookie字节进行传输会严重降低性能
- cookie中包含的是服务器特有的名值对，所以对大部分站点来说，大多数cookie都只是无法识别的无用数据
- 将所有的cookie发送给所有站点会引发潜在的隐私问题

cookie规范有两个不同的版本：cookie版本0和cookie版本1。但二者都不是作为HTTP/1.1规范的一部分提供的。

cookie版本0定义的Set-Cookie响应首部、cookie请求首部以及用于控制cookie的字段

```
Set-Cookie: name=value [; expires=date] [; path=path] [; domain=domain] [; secure]
Cookie: name1=value1 [; name2=value2] ...
```

cookie版本1引入了Set-Cookie2首部Cookie2首部，主要改动包括下列内容

- 为每个cookie关联上解释性文本、对其目的进行解释
- 允许在浏览器退出时，不考虑过期时间、将cookie强制注销
- 用相对秒数，而不是绝对日期来表示cookie的Max-Age
- 通过URL端口号，而不仅仅是域和路径来控制cookie的能力
- 通过Cookie首部回送域、端口和路径过滤器
- 为实现互操作行使用的版本号
- 在Cookie首部从名字中区分出附加关键字的$前缀

Set-Cookie2属性

| Set-Cookie2属性 | 描述及实例                                                   |
| --------------- | ------------------------------------------------------------ |
| NAME=VALUE      | 强制                                                         |
| Version         | 强制，对应cookie规范的版本                                   |
| Comment         |                                                              |
| CommentURL      |                                                              |
| Discard         | 在客户端程序终止时，指示客户端放弃这个cookie                 |
| Domain          | 浏览器指向域中的服务器主机名发送cookie                       |
| Max-Age         |                                                              |
| Path            |                                                              |
| Port            | 单独作为关键使用，也可以包含一个由逗号分隔的、可以应用cookie的端口列表。如果有端口列表，就只能向端口与列表中的端口相互匹配的服务器提供cookie。如果单独提供关键字Port而没有值，就只能向当前响应服务器的端口号提供Cookie |
| Secure          |                                                              |

### 基本认证机制

HTTP提供了一个原生的质询/响应(challenge/response)框架，简化了对用户的认证过程。Web应用程序收到一条HTTP请求报文时，服务器没有按照请求执行动作，而是以一个"认证质询"进行响应，要求用户提供一些保密信息来说明他是谁，从而对其进行质询。用户再次发起请求时，要附上保密证书(用户名和密码)。

HTTP定义了两个官方的认证协议：**基本认证**和**摘要认证**。

| 步骤     | 首部                | 描述                                                         | 方法/状态                 |
| -------- | ------------------- | ------------------------------------------------------------ | ------------------------- |
| 请求质询 | WWW-Authenticate    | 第一条请求没有认证信息<br />服务器用401状态拒绝请求，说明需要用户提供用户名和密码<br />服务器会在WWW-Authenticate首部对保护区域进行描述 | GET<br />401 Unauthorized |
| 授权     | Authorization       | 客户端重新发出请求，附加一个Authorization首部，用来说明认证算法，用户名和密码 | GET                       |
| 成功     | Authentication-Info | 服务器会将文档返回，有些授权算法会在可选的Authentication-Info首部返回一些与授权会话相关的附加信息 | 200 OK                    |

#### Base-64用户名/密码编码

Base-64编码会将一个8位字节序列划分成一些6位的块。用每个6位的块在一个特殊的由64个字符组成的字母表中选择一个字符，这个字母表中包含了大部分字母和数字。

#### 代理认证

中间的代理服务器也可以实现认证功能。这个过程的第一步就是通过代理认证(proxy authentication)来识别身份。

#### 基本认证的安全缺陷

- 基本认证是采用网络以明文的方式发送用户名和密码，容易被别人捕获
- 即使是密文发送 ，也很容易被别人解码
- 适用于很简单的会话服务
- 没有中间节点的保护措施
- 容易假冒服务器骗过基本认证

### 摘要认证

摘要认证对基本认证做了改进

- 永远不会以明文方式在网络上发送密码
- 可以防止恶意用户捕获并重放认证的握手过程
- 可以有选择地防止对报文内容的篡改
- 防范其他几种常见的攻击方式

客户端不会发送密码，而是会发送一个"指纹"或密码的"摘要"，这是密码的不可逆扰码。

#### 用随机数防止重放攻击

仅仅隐藏密码并不能避免危险，因为即便不知道密码，别有用心的人也可以截获摘要，并一编遍地重放给服务器。

为防止此类重放攻击的发生，服务器可以向客户端发送一个称为随机数(nonce)的特殊令牌，这个数经常发生变化(可能是每毫秒，或者是每次认证都变化)。客户端在计算摘要之前要先将这个随机数令牌附加到密码上。

##### 摘要认证握手机制

1. 服务器会计算出一个随机数
2. 服务器将这个随机数放在WWW-Authenticate质询报文中，与服务器所支持的算法列表一同发往客户端
3. 客户端选择一个算法，**计算出密码和其他数据的摘要**
4. 将摘要放在一条Authorization报文中发回服务器。如果客户端要对服务器进行认证，可以发送客户端随机数
5. **服务器接收摘要、选中的算法以及支撑数据，计算出与客户端相同的摘要**。然后服务器将本地生成的摘要与网络传送过来的摘要进行比较，验证其是否匹配。服务器可以预先将下一个随机数计算出来，提前将其传递给客户端，这样下一次客户端就可以预先发送正确的摘要了

#### 摘要的计算

摘要认证的核心就是对公共信息、保密信息和有时限的随机值这个组合的单向摘要。

##### 缓存

共享的缓存收到包含Authorization首部的请求和转接那条请求产生的响应时，除非响应中提供了下列两种Cache-Control指令之一，否则一定不能将那条响应作为对任何其他请求的应答使用

- 原始响应中包含Cache-Control指令must-revalidate，缓存可以在应答后继请求时使用那条响应的实体部分。它首先要用新请求的请求首部，与原始服务器再次进行验证，这样原始服务器就可以对请求进行认证
- 如果原始响应中包含有Cache-Control指令public，在对任意后继请求的应答中都可以返回响应的实体部分

#### 安全性考虑

- 首部篡改

  摘要认证的重点在于提供一种防篡改认证机制，具有一定保护级别的首部只有WWW-Authenticate和Authorization

- 重放攻击

  指的是有人将从某个事务中窃取的认证证书用于另一个事务。缓解问题的方法之一就是让服务器产生的随机数包含根据客户端IP地址时间戳、资源Etag和私有服务器秘钥算法算出的摘要；另一种方法是为每个事务都使用一个唯一的随机数

- 多重认证机制

  服务器支持多重认证机制(比如基本认证和摘要认证)，通常会在WWW-Authenticate首部提供选项。若没有要求客户端选择功能最强的认证机制，那和原来的认证方案就没啥区别。避免出现这个问题的方法就是让客户端总是去选择可用认证方案中功能最强的那个。

- 词典攻击

  词典攻击是典型的密码猜测攻击方法。使用复杂的相对难以破译的密码和合适的密码过期策略才能解决这个问题。

- 恶意代理攻击和中间人攻击

  该攻击采用窃听的形式，可以删除提供的所有选项，用最薄弱的认证策略来取代现有的认证机制，对其进行修改。防止这些攻击唯一简便的方式就是使用SSL

- 选择明文攻击

  使用摘要认证的客户端会用服务器提供的随机数来生成响应。选择明文攻击有以下几种变体形式

  - 预先计算的词典攻击
  - 批量暴力型攻击

### 安全HTTP

HTTPS是最流行的HTTP安全形式。HTTPS方案的URL以https://，而不是http://开头，据此就可以分辨某个Web页面是通过HTTPS而不是HTTP访问的。

使用HTTPS时，所有的HTTP的请求和响应数据在发送到网络之前，都要进行加密。HTTPS在HTTP下面提供了一个传输级的密码安全层(可以使用SSL，也可以使用TLS)。大部分困难的编码及解码工作都是在SSL库中完成的，所以Web客户端和服务器在使用安全HTTP时无需过多地修改器协议处理逻辑。在大多数情况下，只需要SSL的输入/输出调用取代TCP的调用，再增加几个调用来配置和管理安全信息就行了。

#### 数字加密

##### 密码

加密之前的原始报文通常称为明文；使用密码之后的报文通常称为密文。

##### 密钥

在密码机中输入正确的密钥之后，解密过程才能正确进行。密钥会让密码机看起来是有多个虚拟密码机一样，每个密码机都有不同的密钥值，因此其行为都会有所不同。

##### 数字密钥

数字计算的出现，在以下两个方面取得了进展：

- 从机械设备的速度和功能限制中解放出来，使复杂的编/解码算法成为可能
- 支持超大密钥成为可能，从一个加密算法中产生出数万亿的虚拟加密算法，由不同的密钥值来区分不同的算法。密钥越长，编码组合就越多，通过随机猜测密钥来破解代码就越困难

**数字密钥只是一些数字，是编/解码算法的输入。编码算法就是一些函数，这些函数会读取一块数据，并根据算法和密钥值对其进行编/解码。**

给定明文报文P，编码函数E和数字编码密钥e，生成经过编码后的密文C

```
C = E(P, e)
```

给定解码函数D，解码密钥d和密文C，解码出原始明文P

```
P = D(C, d)
```

#### 对称密钥加密技术

对称加密技术就是在编码时使用的密钥值和解码时使用的一样(e == d)，可以将其称为密钥k。

发送端和接收端要共享相同的密钥k才能进行通信。发送端用共享的密钥来加密报文，并将得到的密文发送给接收端。接收端收到密文，并对其应用解密函数和相同的共享密钥，恢复出原始的明文。

常见的对称密钥加密技术有：**DES、Triple-DES、RC2、RC4**。

##### 密钥长度与枚举攻击

对称密钥加密的密钥必须要保密

攻击者会试图用暴力的方式破解密钥值，称为枚举攻击。如果只有几种可能的密钥值，就能很容易的破解。

对于小型的、不太重要的事务来说，40位的密钥就够安全了。128位的密钥被认为是非常强大的。

**对称密钥加密技术的缺点之一就是发送者和接收者在互相对话之前，一定要有一个共享的保密密钥。**并且每对通信实体都需要有自己的密钥，且每个与该实体通信的节点都要记住这个密钥，这个数量将会是难以估量的。

#### 公开密钥加密技术

公开密钥加密技术使用了两个非对称密钥：一个用来对主机报文编码，另一个而用来对主机报文解码。

这样，节点X可以将加密密钥ex告诉访问者，任何想向节点X发送报文的人都可以使用相同的公开密钥。所以公开密钥加密技术避免了对称密钥加密技术中成对密钥数目的N^2扩展问题。

##### RSA

即使有了公共密钥、任意一段明文、用公共密钥对明文编码之后得到的相关密文、RSA算法自身，甚至RSA实现的源代码，破解代码找到相应的私有密钥的难度仍相当于对一个极大的数进行质因数分解的困难程度，这种计算被认为是所有计算机科学中最难的问题之一。

##### 混合加密系统和会话密钥

通常公开密钥加密算法的计算会很慢。实际上会混合使用对称和非对称策略。如，比较常见的做法是在两个节点之间通过便捷的公开密钥加密技术建立起安全通信，然后再用那条安全的通道产生并发送临时的随机对称密钥，通过更快的对称加密技术对其余的数据进行加密。

#### 数字签名

除了加/解密报文之外，还可以用加密系统对报文进行签名(sign)，以说明是谁编写的报文，同时证明报文未被篡改过。这种技术被称为数字签名(digital signing)。

数字签名是附加在报文上的特殊加密校验码。有两个好处

- 签名可以证明是作者编写了这条报文
- 签名可以防止报文被篡改。由于校验和只有作者保密的私有密钥才能产生，所以攻击者无法为篡改了的报文伪造出正确的校验码

**数字签名通常是用非对称公开密钥技术产生的。**

签名过程为：

- 节点A将变长报文提取为定长的摘要
- 节点A对摘要应用"签名"函数，函数会将用户私有密钥作为参数
- 一旦计算出签名，节点A就将其附加在报文的末尾，并将报文和签名都发送给B
- 接收端(节点B)接收井私有密钥扰码的签名，应用公开密钥的反函数。检查摘要版本是否匹配，判断是否在传输过程中被篡改了

#### 数字证书

数字证书中包含了由某个受信任组织的用户或公司的相关信息。

基本的数字证书中通常包含一些纸质ID中常见的内容，如

- 对象的名称(人、服务器、组织等)
- 过期时间
- 证书发布者(由谁为证书担保)
- 来自证书发布者的数字签名

数字证书通常还包括对象的公开密钥，以及对象和所用签名算法的描述性信息。

数字证书是没有统一的全球标准的，但现在使用的大多数证书都以一种标准格式--X.509 v3来存储它们的信息。这个X.509 v3证书提供了一种标准的方式，将证书信息规范至一些可解析字段中。不同类型的证书有不同的字段值，但大部分都遵循X.509 v3结构。

基于X.509证书的签名有好几种

- Web服务器证书
- 客户端电子邮件证书
- 软件代码签名证书
- 证书颁发机构整证书

##### 用证书对服务器进行认证

通过HTTPS建立了一个安全Web事务之后，浏览器都会自动获取所连接服务器的数字证书。如果服务器没有证书，安全连接就会失败。服务器证书包含很多信息：

- Web站点的名称和主机名
- Web站点的公开密钥
- 签名颁发机构的名称
- 来自签名办法机构的签名

浏览器会预先安装一些比较权威的公共签名机构的证书。

如果对签名颁发机构一无所知，就会向用户显示一个对话框，看看他是否相信这个签名发布者。

### HTTPS--细节介绍

HTTPS将HTTP协议与一组强大的对称、非对称和基于证书的加密技术结合在一起，使得HTTPS不仅很安全，而且很灵活，很容易在处于无序状态的、分散的全球互联网上进行管理。

如果URL是https，客户端就会打开一条到服务器端口443(默认情况下)的连接，然后与服务器"握手"，以二进制格式与服务器交换一些SSL安全参数，附上加密的HTTP命令。

SSL是个二进制协议，与HTTP完全不同，其流量是承载另一个端口上的。如果SSL与HTTP流量都从端口80到达，大部分Web服务器会将二进制SSL流量错误理解并关闭连接，实际建立连接是采用隧道方式处理的。

##### SSL握手

在发送已加密的HTTP报文之前，客户端和服务器要进行一次SSL握手，在这个握手过程中，要完成以下工作：

- 交换协议版本号
- 选择一个两端都了解的密码
- 对两端的身份进行认证
- 生成临时的会话密钥，以便加密信道

##### 服务器证书

SSL支持双向认证，将服务器证书承载回客户端，再将客户端的证书回送给服务器。但浏览时并不经常使用客户端证书。大部分用户甚至都没有自己的客户端证书。

安全HTTPS事务总是要求使用服务器证书。服务器证书就是一个显示了组织的名称、地址、服务器DNS域名以及其它信息的X.509 v3派生证书。

##### 站点证书的有效性

SSL自身不要求用户检查Web服务器证书，但浏览器会对证书进行简单的完整性检查，并为用户提供进一步彻查的手段

- 日期检测

  检查证书的起始日期和结束日期，以确保证书仍然有效

- 签名颁发者可信度检测

  每个证书都由某些证书颁发机构(CA)签发的，服务为服务器担保。有些CA是非常著名的组织，浏览器会附带一个签名颁发机构的受信列表。如果浏览器收到了某未知颁发机构签发的证书，那它通常会显示一条警告信息

- 签名检测

  一旦判定签名授权是可信的，浏览器就要对签名使用签名颁发机构的公开密钥，并将其与校验码进行比较，已查看证书的完整性

- 站点身份检测

  大部分浏览器都会尝试着去验证证书中的域名与他们所对话的服务器的域名是否匹配

##### 虚拟主机与证书

对虚拟主机(一台服务器上有多个主机名)站点上安全流量的处理有时是很棘手的。为防止这个问题，一般可以重定向的方式指向服务器证书上的主机名地址。

#### 通过代理以隧道形式传输安全流量

客户端通常会用Web代理服务器代表他们来访问Web服务器。代理是防火墙路由器唯一允许进行HTTP流量交换的设备，可能会进行病毒检测或其他的内容控制工作。

**只要客户端开始用服务器的公开密钥对发往服务器的数据进行加密，代理就再也不能读取HTTP首部了**。代理不能读取HTTP首部，就无法知道应该讲请求转向何处了。

可以使用HTTPS SSL隧道协议，客户端首先告知代理，它想要连接的安全主机和端口，这是在开始加密之前进行的，以明文形式告知，代理可以理解这条信息。

HTTP通过新的名为CONNECT的扩展方法来发送明文形式的端点信息。工作完成之后，直接在客户端和服务器之间以隧道形式传输数据，具体形式如下：

```
CONNECT home.netscape.com: 443 HTTP/1.0
User-agent: Mozilla/1.1N

<raw SSL-encrypted data would follow here...>
```

代理会对请求进行评估，确保是有效的，而且用户有权请求这样一条连接。如果一切正常，代理会建立一条到目标服务器的连接，发回响应：

```
HTTP/1.0 200 Connection established
Proxy-agent: Netscape-Proxy/1.1
```

### 实体和编码

为了更好的描述http所传输数据的类型、大小、有效性等，http协议应该为主体提供以下描述信息：

1. 可以被正确的识别（通过Content-Type首部说明媒体格式），以便接收端能够识别并正确处理内容
2. 是最新的（通过实体验证码和缓存过期控制）
3. 符合用户的需要（基于Accept系列的内容协商首部）
4. 在网络上可以快速有效地传输（通过范围请求、差异编码以及其他数据压缩方法）
5. 完整到达、未被篡改（通过传输编码首部和Content-MD5校验和首部）

HTTP1.1定义了基本实体首部字段有12个：

1. Content-Type:实体中所承载对象的类型
2. Content-Length:所传送实体主体的长度或大小，（注意：**如果主体采取了内容编码进行压缩，那么它所指的是压缩后的长度或大小**，此首部是描述报文主体结束的关键，尤其在持久连接时对多个报文进行正确分段）
3. Content-Language:与所传送对象最相配的人类语言
4. Content-Encoding:对象数据所做的任意变换（比如，压缩）
5. Content-Location:一个备用位置，请求时可通过它来获得对象
6. Content-Range:如果这是部分实体，这个首部说明它是整体的那个部分
7. Content-MD5:实体主体内容的校验和
8. Last-Modified:所传输内容在服务器上创建或最后修改的日期时间
9. Expires:实体主句将要失效的日期时间
10. Allow:改资源所允许的各种请求方法，例如，GET和HEAD
11. ETag:这份文档特定实例的唯一验证码，ETag首部没有正式定义为实体首部，但它对许多涉及实体的操作来说，都是一个重要的首部
12. Cache-Control:指出应该如何缓存该文档。和ETag首部类似，Cache-Control首部没有正式定义为实体首部

#### Content-Length: 实体的大小

Content-Length首部指示出报文中实体主体的字节大小。这个大小是包含了所有内容编码的。**对文本文件进行gzip压缩的话，Content-Length首部就是压缩后的大小，而不是 原始大小。**

除非使用了分块编码，否则Content-Length首部就是带有实体主体的报文必须使用的。使用Content-Length首部是为了能够检测出服务器奔溃而导致的报文截尾，并对共享持久连接的多个报文进行正确分段。

##### 检测截尾

没有Content-Length，客户端无法区分到底是报文结束时正常的连接关闭还是报文传输中由于服务器崩溃而导致的连接关闭。通过Content-Length可以检测报文截尾。

如果缓存服务器收到被截尾的报文却没有识别出截尾的话，它可能会存储不完整的内容并多次使用它来提供服务。缓存代理服务器通常不会为没有显式Content-Length首部的HTTP主体做缓存，以此来减小缓存已截尾报文的风险。

##### Content-Length与持久连接

Content-Length首部对于持久连接是必不可少的。客户端通过Content-Length首部就可以知道报文在何处结束，下一条报文从何处开始。

但采用分块编码(chunked encoding)，使用持久连接可以没有Content-Length首部。

##### 确定实体主体长度的规则

- 如果特定的HTTP报文类型中不允许带有主体，那么就忽略Content-Length首部。常见情况有：1XX、204以及304响应，还有HEAD方法的响应
- 如果报文中含有描述传输编码的Transfer-Encoding首部，那么实体就应由一个称为“零字节块”的特殊模式结束
- 如果报文中，有Content-Length首部而无Transfer-Encoding首部，那么Content-Length就是描述首部的长度。如果有Content-Length首部，同时也有Transfer-Encoding首部，那么就必须忽略Content-Length,因为传输编码会改变实体主体的表示和传输方式（因此可能就会改变传输的字节数）
- 如果报文使用了multipart/byteranges(多部分/字节范围)媒体类型，且无Content-Length首部，那么报文长度有报文去自定界
- 如果以上规则都不匹配，实体的长度就是关闭连接时所得到的的主体的长度。这个值实际上由服务器关闭连接得到。客户端关闭连接将使服务器无法响应

#### 实体摘要

为检测实体主体的数据是否被不经意地修改，发送方可以在生成初始的主体时，生成一个数据的校验和，这样接收方就可以通过检查这个校验和来捕获所有以外的实体修改。

服务器使用Content-MD5首部发送对实体主体运行MD5算法的结果。中间代理和缓存不应当修改或添加这个首部。

#### 媒体类型和字符集

Content-Type首部字段说明了实体主体的MIME类型。

MIME类型由一个主媒体类型(比如，text、image或audio等)后面跟一条斜线以及一个子类型组成，子类型用于进一步描述媒体类型。

Content-Type首部说明的是原始实体主体的媒体类型。如果实体经过内容编码的话，Content-Type首部说明的仍是编码之前的实体主体的类型。

##### 文本的字符编码

Content-Type首部还可以使用可选参数来进一步说明内容的类型。charset参数就是例子。说明把实体中的比特转换为文本文件中的字符的方法：

```
Content-Type: text/html; charset=iso-8859-4
```

##### 多部分媒体类型

MIME中的multipart包含多个报文，它们何在一起作为单一的复杂报文发送。

- 多部分表格提交

  使用Content-Type: multipart/form-data或Content-Type: multipart/mixed首部以及多部分主体来发送这种请求

  ```
  Content-Type: multipart/form-data; boundary=AaB03x
  ```

  boundary说明分隔主体中不同部分所用的字符串

- 多部分范围响应

  使用Content-Type: multipart/byteranges首部和带有不同范围的多部分主体

  响应中用Content-Range做区分多部分

  ```
  Content-Range: bytes 0-174/1441
  ```

#### 内容编码

过程：

1. 生成原始响应报文，有Content-Type和Content-Length首部。
2. 编码服务器对报文进行编码，编码之后同样拥有Content-Type和Content-Length首部,但是Content-Length可能不同（比如主体被压缩了），同时增加了Content-Encoding首部，这样接收端就知道怎样去解码了。
3. 接收端解码，得到原始报文

 Content-Type首部可以且还应出现在报文中。说明了实体的原始格式，一旦实体被解码，要显示的时候，可能还是需要该信息才行。

编码类型有

- gzip - 实体采用GNU zip编码
- compress - 实体采用Unix的文件压缩程序
- deflate - 实体是用zlib的格式压缩的
- identify - 表明没有对实体进行编码

##### Accept-Encoding首部

为了避免服务器使用客户端不支持的编码方式，客户端可以把自己支持的内容编码方式列表放在请求的Accept-Encoding首部里发出去。

#### 传输编码和分块编码

经过内容编码的报文，只是对报文的实体部分进行了编码。而**对于经过传输编码的报文来说，编码作用在整个报文上，报文自身的结构发生了改变。**

HTTP协议定义了Transfer-Encoding(响应)和TE(请求)两个首部俩描述和控制传输编码

- Transfer-Encoding - 告知接收方为了可靠地传输报文，已经对其进行了何种编码
- TE - 告知服务器可以使用哪些传输编码扩展

```
// 请求
GET /new_product.html HTTP/1.1
Host: www.joes-hardware.com
User-Agent: Mozilla/4.61
TE: trailers, chunked

// 响应
HTTP/1.1 200 OK
Transfer-Encoding: chunked
Server: Apache/3.0
```

最新的HTTP规范只定义了一种传输编码，就是分块编码。

##### 分块编码

分块编码把报文分隔为若干个大小已知的块。块之间是紧挨着发送的，这样就不需要再发送之前知道整个报文的大小了。

分块编码主体是动态创建的，服务器可以缓冲它的一部分，发送其大小和相应的块，然后再主体发送完之前重复这个过程。**服务器可以用大小为0的块作为主体结束的信号**，这样就可以继续保持连接，为下一个相应做准备。

每个分块包含一个长度值和该分块的数据。**长度值是十六进制形式并将CRLF与数据分隔开**。

客户端可以发送分块的数据给服务器。若服务器不支持分块编码，可以用411 Length Required响应来拒绝分块请求的准备。

**拖挂(trailer)**

客户端的TE首部中说明可以接受拖挂的话，就可以在分块的报文最后加上拖挂。

```
// 响应参数中包括Trailer
Trailer: Content-MD5<CR><LF>

// 在实体的最后一块后加上拖挂
0<CR><LF>
Content-MD5: xxxxxxxxx<CR><LF>
```

除了Transfer-Encoding、Trailer以及Content-Length首部之外，其他首部都可以作为拖挂发送

内容编码和传输编码是可以同时使用的。

如果服务器收到无法理解的经过传输编码的报文，它应当用501 Unimplemented状态码来回复。

#### 验证码和新鲜度

当文档过期之后，客户端必须向服务器请求一份新的请求。如果内容没有发生变化，客户端就没有必要向服务器发送，继续 使用缓存的副本即可。这种特殊的请求，称为有条件的请求(conditional request)，要求客户端使用验证码来告知服务器它当前拥有的版本号，并仅当它的当前副本不再有效时才要求发送新的副本。

服务器告知客户端内容缓存多长时间，这段时间内就是新鲜的，响应首部有: Expires(过期)和Cache-Control(缓存控制)

- Expires规定文档过期的具体时间

  ```
  Expires: Sun Mar 19 18:59:34 GMT 2019
  ```

  客户端和服务器为了能够正确使用Expires首部，必须同步时钟

- Cache-Control首部可以用秒数来规定文档最长使用期，同时还能使用很多指令

  请求报文类型：

  - no-cache - **在重新向服务器验证之前，不要返回文档的缓存副本**
  - no-store - **不要返回文档的缓存副本**
  - max-age - 缓存中的文档不要超过指定的使用期
  - max-stale - 文档允许过期，但不能超过指令中指定的过期值
  - min-fresh - 响应必须至少在指定的时间之内保持新鲜度
  - no-transform - 文档在发送之前不允许被转换
  - only-if-cached - 只有当文档在缓存中才发送，不要联系原始服务器

  响应报文类型：

  - no-cache - 如果指令伴随一个首部列表的话，那么内容可以被缓存并提供给客户端，但必须剔除所列出的首部。如果没有指定首部，缓存中的副本在没有重新向服务器验证之前不能提供给客户端
  - no-store - 响应不允许被缓存
  - no-transform - 响应在提供给客户端之前不能做任何形式的修改
  - must-revalidate - **响应在提供给客户端之前必须重新向服务器验证**
  - proxy-revalidate
  - max-age - 指定文档可以被缓存的时间以及新鲜度的最长时间
  - s-max-age

##### 有条件的请求与验证码

在很多情况下，原始服务器上的文档仍然与缓存中已过期的副本相同。如果还发送就会浪费网络带宽，给缓存服务器和原始服务器增加不必要的负载。

HTTP为客户端提供了一种方法，仅当资源改变时才会请求副本，这种特殊请求称为有条件的请求。

有条件的请求时通过以"If-"开头的有条件的首部来实现的。仅在条件为真才执行。每个有条件的请求都通过特定的验证码来发挥作用。

有条件的首部If-Modified-Since测试文档实例最后被修改的日期时间，最后被修改的日期时间就是验证码；

有条件的首部If-None-Match测试的是文档的ETag值，它是与实体相关联的一个特殊的关键字。

Last-Modified和ETag是HTTP使用的两种主要验证码。

#### 范围请求

HTTP允许客户端实际只请求文档的一部分，或者说某个范围。请求首部可以使用Range，客户端可以请求多个范围的文档。

服务器可以通过在响应中包含Accept-Ranges首部的形式向客户端说明可以接受的范围请求。

```
// 客户端请求
GET /bigfile.html HTTP/1.1
...

// 服务器
HTTP/1.1 200 OK
Content-type: text/html
Content-length: 65537
Accept-ranges: bytes
...

// 客户端
GET /bigfile.html HTTP/1.1
Range: bytes=20224-
...

// 服务器发出响应
HTTP/1.1 206 partial
Content-Range: bytes=20224-
Accept-ranges: bytes
...
```

Range首部在流行的点对点(p2p)文件共享客户端软件中得到广泛应用，他们从不同的对等实体同时下载多媒体文件的不同部分。

#### 差异编码

差异编码时HTTP协议的一个扩展，他通过交换对象改变的部分而不是完整的对象来优化传输性能。差异编码是一类实例操控，因为它依赖客户端和服务器之间针对特定的对象实例来交换信息。

如果客户端想告诉服务器它愿意接受该页面的差异，只要发送A-IM首部就可以了。A-IM是Accep-Instance-Manipulation(接受实例操控)的缩写。在A-IM首部中，客户端会说明它知道哪些算法可以把差异应用于老版本而得到最新版本。服务端发送回一个特殊的响应代码--226 IM Used，告知客户端它正在发送的是所请求对象的实例操控，而不是那个完整的对象自身。IM(Instance-Manipulation)首部说明用于计算差异的算法；新的ETag首部和Delta-Base首部，说明用于计算差异的基线文档的ETag。

```
// 请求报文
GET /bigfile.html HTTP/1.1
Date: Mon, 01 Feb 2019 12:03:00 GMT

// 响应报文
HTTP/1.1 200 OK
Content-type: text/html
Expires: Mon, 01 Feb 2019 12:03:00 GMT
Etag: xxxxxx
...

// 差异请求报文
GET /bigfile.html HTTP/1.1
If-None-Match: xxxxxx
A-IM: diffe
Date: Tue, 02 Feb 2019 12:03:00 GMT

// 差异响应报文
HTTP/1.1 226 IM Used
IM: diffe
ETag: newxxxxxx
Delta-base: xxxxxx
...
```

差异实例操控类型：

- vcdiff - 用vcdiff算法计算差异
- diffe - 用Unix系统的diff-e命令计算差异
- gdiff - 用gdiff算法计算差异
- gzip - 用gzip算法压缩
- deflate - 用deflate算法压缩
- range 
- identity

差异编码可以减少传输次数，但实现起来可能比较麻烦。支持差异编码的服务器必须保存页面随时间变化的所有不同版本，这样才能指出最新版本与所请求的客户端持有的任意版本之间的差异。实现差异编码所需的额外磁盘空间可能很快就会将减少传输量获得的好处抵消掉。

### 国际化

#### HTTP对国际性内容的支持

服务器可以通过HTTP协议的Content-Type首部中的charset参数和Content-Language首部告知客户端文档的字母表和语言。

客户端需要告知服务器用户理解何种语言，浏览器上安装了何种字母表编码算法。客户端发送Accept-Charset首部和Accept-Languge首部，告知服务器它理解哪些字符集编码算法和语言以及其中的优先顺序。

#### 字符集与HTTP

把二进制码转换为字符要经过两个步骤：

- 文档中的二进制码被转换成字符代码，它表示了特定编码字符集中某个特定编号的字符
- 字符代码用于从编码的字符集中选择特定的元素。这两个步骤使用的算法取决于MIME的charset标记

国际化字符系统的关键目标是把语义(字母)和表示(图形化的显示形式)隔离开来。HTTP只关心字符数据和相关语言及字符集标签的传输。字符形状的显示是由用户的图形显示软件(包括浏览器、操作系统、字体等)完成的。

特定的字符编码方案和特定的已编码字符集组合成一个MIME字符集(MIME charset)。HTTP在Content-Type和Accept-Charset首部中使用标准化的MIME charset标记。

##### Content-Type首部和Charset首部以及META标志

web服务器通过在Content-Type首部中使用charset参数把MIME字符集标记发送给客户端：

```
Content-Type: text/html; charset=iso-2022-jp
```

对于HTML内容来说，可以在描述charset的`<META HTTP-EQUIV="Content-Type">`标记中找到字符集。

```html
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=iso-2022-jp"/>
	<meta lang="jp" />
	<title></title>
</head>
```

##### Accept-Charset首部

HTTP客户端可以使用Accept-Charset请求首部来明确告知服务器它支持哪些字符系统。

为了和MIME标准兼容，响应的字符集是由服务器通过Content-Type响应首部的charset参数带回来的。

#### 多语言字符编码入门

##### 字符编码方案

字符编码方案有以下3中主要类型：

- 固定宽度 - 用固定数量的比特表示每个编码后的字符。能被快速处理，但可能会浪费空间
- 可变宽度(无模态) - 可变宽方式的编码对不同的字符代码数字采用不同数量的比特。对于常用字符，这样可以减少需要的位数，而且还能再允许使用多字节来表示国际性字符的同时，保持对传统8位字符集的兼容性
- 可变宽度(有模态) - 有模态的编码使用特殊的"转义"模式在不同的模态之间切换。如可以用有模态的编码在文本中使用多个互相重叠的字符集。

##### 常见编码方案

- 8位 - 8位固定宽度恒等编码把每个字符代码编码为相应的8位二进制。只能支持有256个字符代码范围的字符集。iso-88859字符集家族系列使用的就是8位恒等编码

- UTF-8(最大可到6个字节长度) - UTF表示UCS变换格式(UCS Transformation Format)。**UTF-8为字符代码值使用的是无模态的变宽编码。**

  | 字符代码的二进制位 | 字节1    | 字节2    | 字节3    | 字节4    | 字节5    | 字节6    |
  | ------------------ | -------- | -------- | -------- | -------- | -------- | -------- |
  | 0-7                | 0ccccccc | -        | -        | -        | -        | -        |
  | 8-11               | 110ccccc | 10cccccc | -        | -        | -        | -        |
  | 12-16              | 1110cccc | 10cccccc | 10cccccc | -        | -        | -        |
  | 17-21              | 11110ccc | 10cccccc | 10cccccc | 10cccccc | -        | -        |
  | 22-26              | 111110cc | 10cccccc | 10cccccc | 10cccccc | 10cccccc | -        |
  | 27-31              | 1111110c | 10cccccc | 10cccccc | 10cccccc | 10cccccc | 10cccccc |

#### 国际化的URI

##### URI字符集合

URI中允许出现的US-ASCII字符的子集，可以被分成保留、未保留以及转义字符这几类。未保留的字符可用于URI允许其出现的任何部分。保留的字符在很多URI中都有特殊的含义。

| 字符类别 | 字符列表                                                     |
| -------- | ------------------------------------------------------------ |
| 未保留   | [A-Za-z0-9] \| "-" \| "_" \| "." \| "!" \| "~" \| "*" \| "'" \| "(" \| ")" |
| 保留     | ";" \| "/" \| "?" \| ":" \| "@" \| "&" \| "=" \| "" \| "$" \| "," |
| 转义     | "%"<HEX><HEX>                                                |

##### 转义和反转义

URI转义提供了一种安全的方式，可以在URI内部插入保留字符以及原本不支持的字符(比如各种空白)。每个转义是一组3字符序列，由百分号(%)后面跟上两个十六进制数字的字符。这两个十六进制数字就表示一个US-ASCII字符的代码。

如在URL中插入一个空白(ASCII 32)，可以用转义%20

### 内容协商与转码

存在3中不同的方法可以决定服务器上哪个页面最适合客户端：

- 让客户端来选择 - 客户端驱动的协商

  服务器实际上有两种方法为客户端提供选项：

  - 发送回一个HTML文档，里面有到该页面的各种版本的链接和每个版本的描述信息。该情况会显示一个带有链接的页面。
  - 发送回HTTP/1.1响应时，使用300 Multiple Choices响应代码。该情况会弹出对话窗口，让用户做选择。

- 服务器自动判定 - 服务器驱动的协商

  两种机制可供HTTP服务器评估发送什么响应给客户端比较合适：

  - 检查内容协商首部集。服务器查看客户端发送的Accept首部集，用相应的响应首部与之匹配

    | 首部            | 描述                       |
    | --------------- | -------------------------- |
    | Accept          | 告知服务器发送何种媒体类型 |
    | Accept-Language | 告知服务器发送何种语言     |
    | Accept-Charset  | 告知服务器发送何种字符集   |
    | Accept-Encoding | 告知服务器采用何种编码     |

    客户端Accept首部集合服务器实体首部对应

    | Accept首部      | 实体首部         |
    | --------------- | ---------------- |
    | Accept          | Content-Type     |
    | Accept-Language | Content-Language |
    | Accept-Charset  | Content-Type     |
    | Accept-Encoding | Content-Encoding |

  - 根据其他(非内容协商)首部进行变通。如服务器根据客户端发送的User-Agent首部来发送响应

    HTTP协议定义了服务器在响应中发送的Vary首部。这个首部告知缓存(还有客户端和所有下游的代理)服务器根据哪些首部来决定发送响应的最佳版本。

- 让中间代理来选 - 透明协商

  透明协商机制试图从服务器上去除服务器驱动协商所需的负载，并用中间代理来代表客户端以使与客户端的报文交换最小化。

  代理缓存可以为通过单个URL访问的文档保存不同的副本。缓存同时进行内容转码。

| 技术       | 工作原理                                             | 优点                                                         | 缺点                                             |
| ---------- | ---------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------ |
| 客户端驱动 | 客户端发起请求，服务器发送可选项的列表，客户端选择   | 在服务器端的实现最容易。客户端可以选择最合适的内容           | 增加时延，为了获得正确的内容，至少要发送两次请求 |
| 服务器驱动 | 服务器检查客户端的请求首部集并决定提供哪个版本的页面 | 比客户端驱动的协商要快。HTTP提供q值机制，允许服务器近似匹配，提供Vary首部供服务器告知下游设备如何对请求估值 | 服务器可能要做猜测                               |
| 透明       | 某个中间设备(通常是缓存代理)代表客户端进行请求协商   | 免除Web服务器的协商开销。比客户端驱动的协商要快              | 还没有正式的规范                                 |

#### 转码

服务器可以把现存的文档转换成某种客户端可用的文档。这种选项称为转码。分为3类：

- 格式转换

  指将数据从 一种格式转换成另一种格式，使之可以被客户端查看。通过HTML到WML的转换，无线设备就可以访问通常供桌面客户端查看的文档了。

  ⚠️内容转换或转码与内容编码或传输编码是不同的，后两者一般用于更高效或安全地传输内容，前两者可使访问设备能够查看内容。

- 信息综合

- 内容注入

  增加文档的内容。例如自动广告生成器和用户追踪系统。

### Web主机托管

对内容资源的存储、协调以及管理的职责称为Web主机托管

#### 虚拟主机托管

许多Web托管者通过让一些顾客共享一台计算机来提供便宜的Web主机托管服务，这称为共享主机托管或虚拟主机托管。每个网站看起来是托管在不同的服务器上，但实际上是托管在同一个物理服务器上。

但HTTP/1.0中存在设计缺陷。规范中没有为共享的Web服务器提供任何方法来识别要访问的是所托管的哪个虚拟网站。

为了解决这个问题，期间出现了4种技术(前2种方案糟糕)

- 通过URL路径进行虚拟主机托管

- 通过端口号进行主机托管

- 通过IP地址进行主机托管

  每个虚拟网站都分配一个或多个唯一的IP地址。所有虚拟网站的IP地址都绑定同一个共享的服务器上。服务器可以查询HTTP连接的目的IP地址，并以此来判断客户端的目标网站。

  但存在问题，对大的托管者来说，虚拟IP的主机托管能够工作，但它会带来一些麻烦

  - 在计算机系统上能绑定的虚拟IP地址通常是有限的
  - IP地址是稀缺资源
  - 托管者通过复制服务器来增加容量时，IP地址短缺的问题就更严重

- 通过Host首部进行主机托管

  为了解决方案3的问题，浏览器和服务器的实现者扩展了HTTP，把原始的主机名提供给服务器。把主机名(和端口号)放在所有请求的Host扩展首部中传送。

  遵循HTTP/1.1标准必须支持Host首部。绝大多数现代浏览器和服务器都支持Host首部，但仍然有一些客户端和服务器(以及网络机器人)不支持它。

#### HTTP/1.1的Host首部

Host首部描述了所请求的资源所在的因特网主机和端口号，注意一下问题

- 如果Host首部不包含端口，就是用地址方案中默认的端口
- 如果URL中包含IP地址，Host首部就应该包含同样的地址
- 如果URL中包含主机名，Host首部就必须包含同样的名字
- 如果URL中包含主机名，Host首部就不应当包含URL中这个主机名对应的IP地址，这样会扰乱虚拟主机托管服务器的工作，在同一个IP地址上堆叠很多虚拟站点
- 如果URL中包含主机名，Host首部就不应当包含这个主机名的其他别名，因为同样会扰乱主机托管服务器的工作
- 如果客户端显式地使用代理服务器，客户端就必须把原始服务器，而不是代理服务器的名字和端口放在Host首部中
- Web客户端必须在所有请求报文中包含Host首部
- Web代理必须在转发请求报文之前，添加Host首部
- HTTP/1.1的Web服务器必须用400状态码来响应所有缺少Host首部字段的HTTP/1.1请求报文

#### 使站点更可靠

- 镜像的服务器集群 - 一排配置相同的Web服务器，互相可以替换。镜像的服务器通常有一个含有原始内容，这个服务器称为主原始服务器(master origin server)。从主原始服务器接收内容的镜像服务器称为复制原始服务器(replica origin server)。一种简单的部署服务器集群的方法是用网络交换机把请求分发给服务器。托管在服务器上的每个网站的IP地址就设置为交换机的IP地址。

  有两种方法把客户端的请求导向特定的服务器

  - HTTP重定向

    该内容的URL会解析到主服务器的IP地址，然后它会发送重定向到复制服务器

  - DNS重定向

    该内容的URL会解析到多个IP地址，DNS服务器可以选择发送给客户端的IP地址

- 内容分发网络 - CDN

- CDN中的反向代理缓存

- CDN中的代理缓存

## SPDY/HTTP2.0

HTTP2.0的目的是通过`支持请求与响应的多路复用`来减少延迟，通过`压缩HTTP首部字段`将协议开销降低至最低，同时增加对`请求优先级`和`服务端推送`的支持，修改了`流量控制`、`错误处理`和`更新机制`。

HTTP2.0增加了`二进制分帧层`，定义了如何封装HTTP消息并在客户端与服务器之间传输。HTTP1.x以换行符作为纯文本的分隔符，HTTP2.0将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。

### 流、消息、帧

- 流 - 已建立的连接上的双向字节流
- 消息 - 与逻辑消息对应的完整的一系列数据帧
- 帧 - HTTP2.0的最小单位，每个帧包含`帧首部`，至少也会标识出当前帧所属的流

所有HTTP2.0通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。每个数据流以消息的形式发送，而消息由一到多个帧组成，这些帧可以乱序发送，然后再根据每个帧首部的流标识符重新组装

### 二进制分帧层

HTTP2.0性能增强的核心，全在于新增的二进制分帧层。定义了如何封装HTTP消息并在客户端与服务器之间传输

![binary-frames](http://www.reyshieh.com/assets/binary-frames.png)

"层"指的是位于套接字接口与应用可见的高层HTTP API之间的一个新机制，HTTP的语义不受影响，不同的是传输期间的编码发生了变化

### 二进制分帧

HTTP2.0建立连接后，客户端与服务端会通过交换帧来通信，帧是基于这个新协议通信的最小单位。所有帧都共享一个8字节的首部，其中包含帧的长度、类型、标志，还有一个保留位和一个31位的流标识符

![http2-binary-summary](http://www.reyshieh.com/assets/http2-binary-summary.png)

- 16位的长度前缀意味着一帧大约可以携带64KB数据，不包括8字节首部
- 8位的类型字段决定如何解释帧其余部分的内容
- 8位的标志字段允许不同的帧类型定义特定于帧的消息标志
- 1位保留字段始终为0
- 31位的流标识符唯一标识HTTP2.0的流

帧类型包括：

- DATA：用于传输HTTP消息体
- HEADERS：用于传输关于流的额外的首部字段
- PRIORITY：用于指定或重新指定引用资源的优先级
- RST_STREAM：用于通知流的非正常终止
- SETTINGS：用于通知两端通信方式的配置数据
- PUSH_PROMISE：用于发出创建流和服务器引用资源的要约
- PING：用于计算往返时间，执行“活性”检查
- GOAWAY：用于通知对端停止在当前连接中创建流
- WINDOW_UPDATE：用于针对个别流或个别连接实现流量控制
- CONTINUATION：用于继续一系列首部块片段

利用GOAWAY类型的帧，告诉客户端要处理的最后一个流ID，从而消除一些请求竞争，而且浏览器也可以据此智能地重试或取消"悬着的"请求，这是保证复用连接的一个重要功能

在发送应用数据之前，必须创建一个**新流**并随之发送相应的元数据，比如流优先级、HTTP首部等。HTTP2.0规定客户端和服务器都可以发起新流，存在两种可能：

- 客户端通过发送HEADERS帧来发起新流，帧包含带有新流ID的公用首部、可选的31位优先值，以及一组HTTP键-值对首部

  ![http2-headers-priority](http://www.reyshieh.com/assets/http2-headers-priority.png)

- 服务器通过发送PUSH_PROMISE帧来发起推送流，和HEADERS帧等效，但包含"要约流ID"，没有优先值

- HEADERS帧和PUSH_PROMISE帧都只用于沟通新流的元数据，净荷会在DATA帧中单独发送。规定，客户端发送的流具有奇数ID，服务器发起的流具有偶数ID。两端的流ID不会冲突，各自持有一个简单的计数器

### 多向请求与响应

二进制分帧层的加入，实现了多向请求和响应，客户端和服务器可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来

![http2-request-mor](http://www.reyshieh.com/assets/http2-request-more.png)

>注意，HTTP2.0加入了多向请求与响应，为了优化HTTP1.x的方案，如拼接文件、图片精灵、域名分区都变得没有必要。而且这些优化有可能反而带来更大的消耗。同时这个方式减少TCP连接的数量，也会减少客户端和服务器CPU及内存占用

### 请求优先级

每个流都可以带有一个31比特的优先值：

- 0表示最高优先级
- 2^31 - 1表示最低优先级

客户端和服务器可以在处理不同的流时采用不同的策略，以最优的方式发送流、消息和帧。

HTTP2.0并没有规定处理优先级的具体算法，只是提供了一种赋予数据优先级的机制。因此，对应的次序排定策略可能因客户端或服务器的实现而不同：客户端应该明确指定优先值，服务器应该根据该值处理和交付数据

但是，同样还是要考虑些问题。如果服务器不去理会所有优先值，那么可能会导致应用响应变慢，浏览器在需要等关键CSS和JS时，服务器却发送了图片，造成渲染阻塞。但是严格的优先级次序也可能带来次优的效果，因为可能又会引入队首阻塞问题，即某个高优先级的慢请求会不必要地阻塞其他资源的交付

因此，服务器可以交错发送不同优先级的帧。只要可能，高优先级流都应该优先，包括分配处理资源和客户端与服务器间的带宽

### 流量控制

HTTP2.0为数据流和连接的流量控制提供了一个简单的机制：

- 流量控制基于每一跳进行，并不是端到端的控制
- 流量控制基于窗口更新帧进行，即接收方广播自己准备接收某个数据流的多少字节，以及对整个连接要接收多少字节
- 流量控制窗口大小通过WINDOW_UPDATE帧更新，字段指定了流ID和窗口大小递增值
- 流量控制有方向性，即接收方可能根据自己的情况为每个流乃至整个连接设置任意窗口大小
- 流量控制可以由接收方禁用，包括针对个别的流和针对整个连接

### 服务端推送

HTTP2.0允许服务器对客户端请求发送多个响应。除了最初请求的响应外，服务器还可以额外向客户端推送资源，无需客户端明确地请求

服务器将资源直接推送给客户端，带来了好处：

- 客户端可以缓存推送过来的资源
- 客户端可以拒绝推送过来的资源
- 推送资源可以由不同的页面共享
- 服务器可以按照优先级推送资源

推送的资源必须遵循同源策略。服务器不能随便讲第三方资源推送给客户端，必须是经过双方确认的才行

推送的资源将直接进入客户端缓存

### 首部压缩

HTTP2.0在客户端和服务器端使用"首部表"来跟踪和存储之前发送的键-值对，相同的数据不再通过每次请求和响应发送

首部表在HTTP2.0的链接存续期内始终存在，由客户端和服务器共同渐进地更新

每个新的首部键-值对要么被追加到当前表的末尾，要么替换表中的值

![http2-header-diff](http://www.reyshieh.com/assets/http2-header-diff.png)

### HTTP2.0升级与发现

因为HTTP1.x在短时间内是不会去除的，存在很长一段时间内HTTP1.x和HTTP2.0并存。于是，支持HTTP2.0的客户端在发起请求之前，必须能发现服务器及所有中间设备是否支持HTTP2.0协议。存在三种情况：

- 通过TLS和ALPN(应用层协议协商，Application Layer Protocol Negotiation)发起新的HTTPS连接
- 根据之前的信息发送新的HTTP连接
- 没有之前的信息而发起新的HTTP连接

减少网络延迟是HTTP2.0的关键条件，因此在建立HTTPS连接时一定会用到ALPN协商

HTTP1.0和HTTP2.0都使用同一个端口(80)，且没有服务器是否支持HTTP2.0的其他任何信息，此时客户端只能使用HTTP upgrade机制通过协调确定适当的协议

```
GET /page HTTP/1.1
Host server.example.com
Connection: Upgrade, HTTP2-Settings
Upgrade: HTTP/2.0
HTTP2-Settings: (SETTINGS payload)

// 响应 http1.1方式
HTTP/1.1 200 OK
Content-length: 243
Content-type: text/html
// 响应 http2.0方式
HTTP/1.1 101 Switching Protocols
Connection: Upgrade
Upgrade: HTTP/2.0
```

如果客户端因为自己保存有或通过其他手段（如DNS记录、手工配置等）获得了关于HTTP2.0的支持信息，也可以直接发送HTTP2.0分帧，而不必依赖Upgrade机制

最坏的情况就是无法建立连接，客户端再回退一步。重新使用Upgrade首部，或者切换到带ALPN协商的TLS信道

### HTTP1.x和2.0相互转换

如果客户端与服务器端不能保证两端同事支持HTTP2.0，那么可以新增一个转换层，使1.x服务器利用HTTP2.0

一台服务器可以接受HTTP2.0会话，处理之后再向既有基础设施分派1.x格式的请求。接到响应后，再将其转换成HTTP2.0的流返回给客户端